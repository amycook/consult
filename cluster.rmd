---
title: "clusters"
output: word_document
---

```{r, echo=FALSE, include=FALSE}

library('knitr', lib = 'C:/Progra~1/R/R-3.2.1/library')
library('ggplot2', lib = 'C:/Progra~1/R/R-3.2.1/library')
library("plyr",lib = 'C:/Progra~1/R/R-3.2.1/library')
library("dplyr",lib = 'C:/Progra~1/R/R-3.2.1/library')
library('magrittr',lib='C:/Progra~1/R/R-3.2.1/library')
library('reshape2',lib='C:/Progra~1/R/R-3.2.1/library')
library("rpart",lib = 'C:/Program Files/R/R-3.2.1/library')
library('car', lib = 'C:/Progra~1/R/R-3.2.1/library')
library('e1071', lib = 'C:/Progra~1/R/R-3.2.1/library')
library('corrgram', lib = 'C:/Progra~1/R/R-3.2.1/library')
library('party', lib = 'C:/Progra~1/R/R-3.2.1/library')
library('randomForest', lib = 'C:/Progra~1/R/R-3.2.1/library')

# library('knitr')
# library('ggplot2')
# library("dplyr")
# library("plyr")
# library('magrittr')
# library('reshape2')
# library("rpart")
# library('car')
# library('e1071')
# library('corrgram')
# library('party')
# library('dendextend')
# 
# setwd("~/OneDrive/shared files/Bligh Tanner/masters/data")
# setwd("C:/Users/n9232371/Documents/Consultbusiness/data")
# opts_knit$set(root.dir= "~/OneDrive/shared files/Bligh Tanner/masters/data")
opts_knit$set(root.dir= "C:/Users/n9232371/Documents/Consultbusiness/data")
all7c<- read.csv('C:/Users/n9232371/Documents/Consultbusiness/data/all7c.csv')[,-1]
all7c$Post.Code<- as.factor(all7c$Post.Code)

```

Cluster exploration!!

time to have a look at if some of these variables with many many categories can be simplified

Remaining categories include:

Full:

inv.mlsto
timespan
no.users
Discipline
pc.pro
client.totinv
code.director
Num.disc
Business
Biz.type

Many NA:

code.contact
code.client
Project.Value
JD.Second
Billing.Type
Post.Code
code.ProjEng
Billing.Type
majority.pos
pc.majpos



Create reduced dataset and have a think about what you want to cluster against each other

```{r final_var, include=FALSE}

all7d<- all7c %>% select(inv.mlsto, timespan, no.users, Discipline, pc.pro, client.totinv, code.director, 
                         Num.disc, Business,
                         Biz.type, code.contact, pc.majpos,
                         code.client, Project.Value, JD.Second, Billing.Type, Post.Code, code.ProjEng, 
                         Billing.Type, majority.pos)

```

What kind of clusters are you looking for? Within the numeric variables:

```{r, include=FALSE}
all7c[,!sapply(all7c, is.factor)] %>% colnames
all7d[,!sapply(all7d, is.factor)] %>% colnames

```


Numeric variables in reduced dataset are: inv.mlsto, timespan, no.users, pc.pro, client.totinv, Num.disc, Project.Value, pc.majpos

Numeric variables worth considering in full dataset: Num.days, mean.peeps, hours.perday, balance.mlsto, hrs.mlsto, cost.mlsto, 

So, lets choose:

* inv.mlsto
* timespan
* no.users
* pc.pro
* client.totinv
* Num.disc
* Num.days
* mean.peeps
* hours.perday
* balance.mlsto
* hrs.mlsto
* cost.mlsto

Many NA - do second
* pc.majpos
* Project.Value

Before clustering, need to standardise variables, and have a look at 'normality' of other variables

```{r var_check, include=FALSE}

# #Q-Q plot of each variable
# clust<- all7c %>% select(mlsto, inv.mlsto, timespan, no.users, pc.pro, client.totinv,
#                          Num.disc, Num.days, mean.peeps, hours.perday, balance.mlsto, hrs.mlsto,
#                          cost.mlsto, pc.majpos, return.pdol)
# 
# #get rid of zeroes for log transform
# 
# clust[clust$timespan ==0,]$timespan <- 1
# clust[clust$pc.pro ==0,]$pc.pro <- 5
# clust[clust$hours.perday ==0,]$hours.perday <- .1
# clust[clust$hours.perday ==0,]$hours.perday <- .1
# clust[clust$balance.mlsto ==0,]$balance.mlsto <- 1
# clust[clust$hrs.mlsto ==0,]$hrs.mlsto <- 1
# clust[clust$cost.mlsto ==0,]$cost.mlsto <- 1
# clust[clust$return.pdol ==0,]$return.pdol <- .01
# 
# for(i in 1:ncol(clust)){
# qqPlot(clust[,i],
#        main=colnames(clust)[i])
# }
# 
# #qqplots for log of each variable
# for(i in 2:ncol(clust)+1){
# qqPlot(clust[,i] %>% log,
#        main=colnames(clust)[i])
# }
# 
# #qqplots for sqrt of each variable
# for(i in 2:ncol(clust[,-1])+1){
# qqPlot(clust[,i] %>% sqrt,
#        main=colnames(clust)[i])
# }
# 
# #density plots - plain variables
# for(i in 1:ncol(clust)){
# print(
#         ggplot(clust, aes_string(x=colnames(clust[i]))) + geom_histogram(aes(y=..density..))
#         )
# }
# #density plots - log transformed variables
# clust.log<- log(clust)
# for(i in 1:ncol(clust.log)){
#         print(
#                 ggplot(clust.log, aes_string(x=colnames(clust.log[i]))) + geom_histogram(aes(y=..density..))
#                 )
# }
# 
# #plot sqrt of timespan
# clust$timespan <- clust$timespan %>% sqrt
# ggplot(clust, aes_string(x='timespan')) + geom_histogram(aes(y=..density..))

```

taking the log worked for:
* cost.mlsto, hrs.mlsto, hours.perday, Num.days, client.totinv, no.users, inv.mlsto
* sqrt of timespan

so we end up with a numeric data set with the above variables log transformed.
Then scale each by subtracting the mean of each variable and then dividing by the sd of each variable.

```{r clust final, include=FALSE}
clust<- all7c %>% select(mlsto, inv.mlsto, timespan, no.users, pc.pro, client.totinv,
                         Num.disc, Num.days, mean.peeps, hours.perday, balance.mlsto, hrs.mlsto,
                         cost.mlsto, return.pdol)

#get rid of zeroes for log transform

clust[clust$timespan ==0,]$timespan <- 1
clust[clust$hours.perday ==0,]$hours.perday <- .1
clust[clust$hrs.mlsto ==0,]$hrs.mlsto <- 1
clust[clust$cost.mlsto ==0,]$cost.mlsto <- 1

#take log of all variables to be logged in a for loop
logged<- c('cost.mlsto', 'hrs.mlsto', 'hours.perday', 'Num.days', 'client.totinv',
           'no.users', 'inv.mlsto')
for(i in 1:length(logged)){
        clust[,logged[i]]<- clust[,logged[i]] %>% log
}
clust$timespan<- sqrt(clust$timespan)

#now to standardise
clust<- cbind(scale(clust[,-1]) %>% as.data.frame, 'mlsto'=clust$mlsto)
```

Now to do hierarchical clustering

```{r hierarch, include=FALSE}

#Ward's clustering

x<- dist(clust %>% select(-mlsto), method = 'euclidean')
fit<- hclust(x, method = 'ward.D2')
plot(fit)

rect.hclust(fit, k=5, border='red')
#5 clusters looks pretty good

#try horizontal dend with branches coloured for 8 clusters - very slow
# dend<- fit %>% as.dendrogram
# dend %>% color_branches(k=8) %>% plot(horiz=T)
# rect.dendrogram(dend, k=8, horiz=T)

#how many points in each cluster?
clust$groups<- cutree(fit,k=5)
table(clust$groups)



```

Now look at properties of groups using k means clustering

```{r kmeans, include=FALSE}

# k1<- kmeans(clust %>% select(-groups, -mlsto), 5)
# k1.centres<- k1$centers %>% as.data.frame
# k1.centres$group<- rownames(k1.centres)
# k1.melt<- melt(k1.centres)
# k1.melt$group<- k1.melt$group %>% as.factor
# ggplot(k1.melt, aes(x=variable, y= value, fill=variable)) + geom_bar(stat='identity', position='dodge')+
#         facet_wrap(~group) +
#         theme(axis.text.x=element_text(angle=45,hjust=1))
# 
# #try plotting means of actual values
# 
# all7c$groups<- k1$cluster
# kmeans.plot<- all7c %>% select(inv.mlsto, timespan, no.users, pc.pro, client.totinv,
#                          Num.disc, Num.days, mean.peeps, hours.perday, balance.mlsto, hrs.mlsto,
#                          cost.mlsto, return.pdol, groups)
# all7c.plot<- ddply(kmeans.plot, .(groups), numcolwise(mean))
# all7c.plot$groups<- rownames(all7c.plot)
# k2.melt<- melt(all7c.plot)
# 
# #summary means of all numeric variables in 5 clusters
# clust.summary<- all7c.plot %>% select(-groups) %>% round(2)
# tab<- table(all7c$groups) %>% prop.table %>% as.data.frame
# bal<- sum(all7c$balance.mlsto)
# hrs<-  sum(all7c$hrs.mlsto)
# clust.summary$pc.jobs<- round( tab[,2]*100, 1)
# clust.summary$bal.pc<- ddply(all7c, .(groups), summarise, bal.pc= round(sum(balance.mlsto)/bal*100, 1)) %>% 
#         select(2)
# clust.summary$hrs.pc<- ddply(all7c, .(groups), summarise, hrs.pc= round(sum(hrs.mlsto)/hrs*100, 1)) %>% 
#         select(2)
# 
# clust.summary<- clust.summary[,c(1,12,10,11, 13, 9,2,7,6,3,4,8,5,14:16)]
# 
# # add medians
# all7c.med<- ddply(kmeans.plot, .(groups), numcolwise(median))
# 
# all7c.med<- all7c.med[, c(2,13,11,12,14,10,3,8,7,4,5,9,6)]


```


Very interesting, now want to optimise number of clusters- refer wards tutorial

```{r optimise clustnum,include=FALSE}
library('fpc', lib='C:/Progra~1/R/R-3.2.0/library')
library('vegan', lib = 'C:/Progra~1/R/R-3.2.0/library')

#try clustering a low number of numeric variables, trialling iffy ones to see which ones are good for clustering
clust.km<- cascadeKM(clust %>% select(inv.mlsto, balance.mlsto, return.pdol,
                                      hrs.mlsto), 2, 20, iter= 100)
plot(clust.km, sortg = TRUE, grpmts.plot = TRUE)
# client.totinv indicating about 4 clusters
# Num.days - good, indicating 18 custers
# hrs.mlsto - ok, heavy dip, good at about 17 clusters
# pc.pro - 5 groups good, still iffy
# mean.peeps - good at about 4 clusters
# Num.disc - ok, inidicating 12 groups
# timespan: not good for clustering
# no.users: not good for clustering
# hours.perday: no good for clustering

## try out all iffy variables together, eliminate duds
# clust.km<- cascadeKM(clust %>% select(inv.mlsto, balance.mlsto, return.pdol,
#                                       client.totinv, Num.days, hrs.mlsto, pc.pro, mean.peeps,
#                                       Num.disc), 2, 20, iter= 100)
# plot(clust.km, sortg = TRUE, grpmts.plot = TRUE)
# # all together, no good
# # smaller subset of variables I am most interested in that still works for clustering:
# 
# clust.km<- cascadeKM(clust %>% select(inv.mlsto, balance.mlsto, return.pdol,
#                                       hrs.mlsto
#                                       ), 2, 20, iter= 100)
# plot(clust.km, sortg = TRUE, grpmts.plot = TRUE)
# 
# # 17 clusters
# # Cluster cohesion: create plots of SSE index (distance within clusters - sum of squared error) 
# # then calinksi (index of cluster homogeneity and distance where higher number is better)
# # calinski: between cluster distance/within cluster distance
# ind.plot<- melt(clust.km$results)
# ggplot(ind.plot %>% filter(Var1 == 'SSE'), aes(x=Var2, y=value, group=1)) + 
#         geom_line( ) +
#         theme(axis.text.x=element_text(angle=45,hjust=1))
# ggplot(ind.plot %>% filter(Var1 == 'calinski'), aes(x=Var2, y=value, group=1)) + 
#         geom_line( )+
#         theme(axis.text.x=element_text(angle=45,hjust=1))
# 17 clusters should be good


```

Analysis shows that inv.mlsto, balance.mlsto, return.pdol, and hrs.mlsto should be used for clustering and that 17 clusters is ideal.
I'm not completely happy with the clustering.
I think I should now add a new variable: inv.mlsto x return.pdol
This will give a 'success' scale, weighing large jobs even with a smaller return.pdol as quite good and tiny jobs with a good return.pdol as average to low.

this means I will need to check normality, scale the variable before adding it to clust

```{r new var, include=FALSE}
#new variable for all7c - success
# success= return.pdolxinv.mlsto

all7c<- transform(all7c, suc= inv.mlsto*return.pdol)
# all7c$suc %>% summary

# all7c %>% arrange(-suc) %>% head

qqPlot(all7c$return.pdol,
       main='success')

qqPlot(sapply(all7c$suc, function(x){sign(x)*log(abs(x) + 1)}))

#density plots - plain variables

ggplot(all7c, aes_string(x='inv.vs.cost')) + geom_histogram(aes(y=..density..))

#density plots - log transformed variables

trial<- (sapply(all7c$suc, function(x){sign(x)*log(abs(x) + 1)})) %>% as.data.frame
colnames(trial)[names(trial) %in% '.']<-'var'
ggplot(trial, aes_string(x='var')) + geom_histogram(aes(y=..density..))
skewness(trial$var)
kurtosis(trial$var)
mean(trial$var)
sd(trial$var)
trial$scale.var<- trial$var/sd(trial$var)
ggplot(trial, aes_string(x='scale.var')) + geom_histogram(aes(y=..density..))
# ggplot still looks bimodal after scaling

## conclusion - lets take neglog of suc and scale it, add it to clust

clust$suc<- sapply(all7c$suc, function(x){sign(x)*log(abs(x) + 1)})
clust$suc<- clust$suc/sd(clust$suc)

## should we make return.pdol bimodal??
math.cbrt <- function(x) {
        sign(x) * abs(x)^(1/3)
}
qqPlot(all7c$return.pdol %>% math.cbrt,
       main='success')
trial<- (all7c$return.pdol %>% math.cbrt) %>% as.data.frame
colnames(trial)[names(trial) %in% '.']<-'var'
ggplot(trial, aes_string(x='var')) + geom_histogram(aes(y=..density..))
skewness(trial$var)
kurtosis(trial$var)
trial$scale.var<- trial$var/sd(trial$var)
ggplot(trial, aes_string(x='scale.var')) + geom_histogram(aes(y=..density..))
#take cube root of return.pdol and scale it to clust

clust$return.pdol<- math.cbrt(all7c$return.pdol)
clust$return.pdol<- all7c$return.pdol/sd(all7c$return.pdol)

## should we make balance.mlsto bimodal??

qqPlot(all7c$balance.mlsto,
       main='balance')
qqPlot(sapply(all7c$balance.mlsto, function(x){sign(x)*log(abs(x) + 1)}),
       main='balance')
trial<- (sapply(all7c$balance.mlsto, function(x){sign(x)*log(abs(x) + 1)})) %>% as.data.frame
colnames(trial)[names(trial) %in% '.']<-'var'
ggplot(trial, aes_string(x='var')) + geom_histogram(aes(y=..density..))
skewness(trial$var)
kurtosis(trial$var)
trial$scale.var<- trial$var/sd(trial$var)
ggplot(trial, aes_string(x='scale.var')) + geom_histogram(aes(y=..density..))
#take cube root of return.pdol and scale it to clust

clust$balance.mlsto<- sapply(all7c$balance.mlsto, function(x){sign(x)*log(abs(x) + 1)})
clust$balance.mlsto<- clust$balance.mlsto/sd(clust$balance.mlsto)

```


Repeat clustering with new suc and revised bi-modal return.pdol

```{r new successvar, echo=FALSE}

#investigate new variable a little

clust.km<- cascadeKM(clust %>% select(inv.mlsto, balance.mlsto), 2, 30, iter= 100)
plot(clust.km, sortg = TRUE, grpmts.plot = TRUE)

# 11 clusters
# Cluster cohesion: create plots of SSE index (distance within clusters - sum of squared error) 
# then calinksi (index of cluster homogeneity and distance where higher number is better)
# calinski: between cluster distance/within cluster distance
ind.plot<- melt(clust.km$results)
ggplot(ind.plot %>% filter(Var1 == 'SSE'), aes(x=Var2, y=value, group=1)) + 
        geom_line( ) +
        theme(axis.text.x=element_text(angle=45,hjust=1))
ggplot(ind.plot %>% filter(Var1 == 'calinski'), aes(x=Var2, y=value, group=1)) + 
        geom_line( )+
        theme(axis.text.x=element_text(angle=45,hjust=1))

# 16 clusters should be good

# have a look at dendrogram with 16 clusters

x<- dist(clust %>% select(inv.mlsto, balance.mlsto), 
         method = 'euclidean')
fit<- hclust(x, method = 'ward.D2')
plot(fit)

rect.hclust(fit, k=16, border='red')

#looks good!

```

now want 16 clusters, based on k means optimisation, have a look at average characteristics

```{r, echo=FALSE}

k1<- kmeans(clust %>% select(inv.mlsto, balance.mlsto), 16)

#try plotting means of actual values

all7c$group.num<- k1$cluster
kmeans.plot<- all7c %>% select(inv.mlsto, timespan, no.users, pc.pro, client.totinv,
                         Num.disc, Num.days, mean.peeps, hours.perday, balance.mlsto, hrs.mlsto,
                         cost.mlsto, return.pdol, suc, group.num)
all7c.plot<- ddply(kmeans.plot, .(group.num), numcolwise(mean))
all7c.plot$group.num<- rownames(all7c.plot)
k2.melt<- melt(all7c.plot)

#summary means of all numeric variables in 5 clusters
clust.summary<- all7c.plot %>% select(-group.num) %>% round(2)
tab<- table(all7c$group.num) %>% prop.table %>% as.data.frame
bal<- sum(all7c$balance.mlsto)
hrs<-  sum(all7c$hrs.mlsto)
clust.summary$pc.jobs<- round( tab[,2]*100, 1)
clust.summary$bal.pc<- ddply(all7c, .(group.num), summarise, bal.pc= round(sum(balance.mlsto)/bal*100, 1)) %>% 
        select(2)
clust.summary$hrs.pc<- ddply(all7c, .(group.num), summarise, hrs.pc= round(sum(hrs.mlsto)/hrs*100, 1)) %>% 
        select(2)
clust.summary$job.count<- table(all7c$group.num) %>% as.data.frame %>% select(Freq)

clust.summary<- clust.summary %>% select(inv.mlsto, suc, return.pdol, cost.mlsto, balance.mlsto,
                                         hrs.mlsto, hours.perday, timespan, Num.days, Num.disc,
                                         no.users, pc.pro, mean.peeps, client.totinv, pc.jobs,
                                         bal.pc, hrs.pc, job.count)

# add medians
all7c.med<- ddply(kmeans.plot, .(group.num), numcolwise(median)) %>% round(2)

all7c.med<- all7c.med %>% select(inv.mlsto, suc, return.pdol, cost.mlsto, balance.mlsto, hrs.mlsto, hours.perday, timespan, Num.days, Num.disc, no.users, pc.pro, mean.peeps, client.totinv)

clust.summary<- cbind(all7c.med %>% select(inv.mlsto, suc, return.pdol, cost.mlsto, balance.mlsto,
                                     hrs.mlsto, hours.perday, timespan, Num.days, Num.disc,
                                     no.users, pc.pro, mean.peeps, client.totinv),
                      clust.summary %>% select(pc.jobs,bal.pc, hrs.pc, job.count))

clust.summary$bal<- ddply(all7c, .(group.num), summarise, bal= round(sum(balance.mlsto), 1)) %>% 
        select(2)

#investigate clusters
all7c[all7c$group.num == 12,] %>% select(inv.mlsto, suc, pc.majpos, majority.pos,
                                         code.client, client.meaninv, code.director, code.ProjEng,
                                         return.pdol, balance.mlsto, Year, timespan, pc.pro,
                                         pc.director, JD.Second, Business, client.count, Discipline,
                                         code.client, Billing.Type) %>% summary

```

Visualise confidence intervals in terms of 'success'

```{r CI, echo=FALSE}
library('RcmdrPlugin.BCA',lib='C:/Progra~1/R/R-3.2.1/library')
# principal component analysis

#add clust columns to all7c
all7c$clust.inv<- clust$inv.mlsto
all7c$clust.bal<- clust$balance.mlsto
all7c$clust.cost<- clust$cost.mlsto
all7c$clust.return<- clust$return.pdol
all7c$clust.hours<- clust$hrs.mlsto
all7c$clust.suc<- clust$suc


#convert cluster groups to integer

all7c$group.num<- as.integer(all7c$group.num)
p<- prcomp(~clust.inv + clust.bal+ clust.cost, data=all7c, centre=T)
# summary(p)
biplot(p, xlabs = as.character(all7c$group.num))
#putlers in-house biplot shows centroids
bpCent(p, clsAsgn = all7c$group.num, centroids=TRUE, xlabs = as.character(all7c$Business))

##try ggbiplot
library(devtools,lib='C:/Progra~1/R/R-3.2.1/library')
library('ggbiplot',lib='C:/Progra~1/R/R-3.2.1/library')
#visualise clusters
q<- ggbiplot(p, obs.scale = 1, var.scale = 1, 
              groups = all7c$group.num %>% as.factor, ellipse = TRUE,
             labels = all7c$Business,
              circle = TRUE)
q <- q + scale_color_discrete(name = '')
q <- q + theme(legend.direction = 'vertical', 
               legend.position = 'right')
q

#visualise factors within clusters
g<- ggbiplot(p, obs.scale = 1, var.scale = 1, 
              groups = all7c$Business %>% as.factor(), ellipse = TRUE, 
              circle = TRUE)
g <- g + scale_color_discrete(name = '')
g <- g + theme(legend.direction = 'vertical', 
               legend.position = 'right')
g

#confusion matrix of groups vs. categorical variables

#Business
table(all7c$group.num, all7c$Business)
#notes
# only single NFP - combine to institution
all7c[all7c$Business %in% 'NFP',]$Business<- 'institution'
#combine person and friend
all7c[all7c$Business %in% 'friend',]$Business<- 'person'
#fabricator labelled manufactorer/supplier
all7c[all7c$Business %in% 'fabricator',]$Business<- 'manufacturer/supplier'
all7c[all7c$Business %in% 'membrane fabricator',]$Business<- 'manufacturer/supplier'
#combine remedial building services to building services
all7c[all7c$Business %in% 'remedial building service',]$Business<- 'building services'
#combine gov and council
all7c[all7c$Business %in% 'council',]$Business<- 'gov'
all7c$Business<- droplevels(all7c$Business)


```

View counts of each category in each group as a heatmap

Order groups by profitability and size





