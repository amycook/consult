---
title: "Boosted"
author: "Amy Cook"
date: "October 19, 2015"
output: word_document
---


```{r, load library and packages, include= FALSE}
library("plyr",lib = 'C:/Progra~1/R/R-3.2.1/library')
library("dplyr",lib = 'C:/Progra~1/R/R-3.2.1/library')
library('magrittr',lib='C:/Progra~1/R/R-3.2.1/library')
library('reshape2',lib='C:/Progra~1/R/R-3.2.1/library')
library('ggplot2',lib='C:/Progra~1/R/R-3.2.1/library')
library('gbm', lib = 'C:/Progra~1/R/R-3.2.2/library')
library('caret', lib = 'C:/Progra~1/R/R-3.2.2/library')
library('ROCR',lib='C:/Progra~1/R/R-3.2.2/library')

# setwd("C:/Users/n9232371/Documents/Consultbusiness/data")
```

Read in data. Change return.pdol to 0,1 variable

```{r, echo=FALSE}
all8a<- read.csv('C:/Users/n9232371/Documents/Consultbusiness/data/all8a.csv')[,-1]

all8a$b.rpdol<- all8a$return.pdol 
all8a$b.rpdol<- ifelse(all8a$return.pdol<=0, 1, 0)
all8a$timespan.cbrt <- ifelse(all8a$timespan.cbrt ==0, 1, all8a$timespan.cbrt)

summary(all8a$b.rpdol)

all9a<- all8a
write.csv(all9a, 'C:/Users/n9232371/Documents/Consultbusiness/data/all9a.csv')
all9a<- read.csv('C:/Users/n9232371/Documents/Consultbusiness/data/all9a.csv')[,-1]

```


Create test and train sample

```{r, echo=FALSE}
set.seed(200)
sample<- sample(1:nrow(all9a), 2/3*nrow(all9a), replace=F)
train<- all9a[sample,]
test<- all9a[-sample,]

```

Try building a boosted tree wihtout any training

```{r, echo=FALSE}
boost.1 <- gbm(b.rpdol~.- mlsto - return.pdol-Year-code.contact - code.client, 
               distribution = "bernoulli", data=train,
          n.trees = 10000,
          shrinkage = 0.001,
          interaction.depth = 1,
          n.minobsinnode = 10,
          bag.fraction = 0.5)

print(boost.1)
summary(boost.1)

#look at first tree
pretty.gbm.tree(boost.1,9000)
boost.1$var.names

#view OOB error plot
gbm.perf(boost.1, method="OOB", plot.it=TRUE)
#error still rapidly reducing at 10000 trees

#partial dependence plots:
i=8
a<- plot.gbm(boost.1, i, type="response")
a
#Discipline, Business, inv.mlsto.log, client.totinv.log, Billing.Type dont matter?


```

First tune shrinkage and plot. Get rid of year because in future, won't have historical data on year..

Try deleting code.client variable

```{r, echo=FALSE}

#tune which variables should be included!!
vars.excl = c("JD.Second", "Business", "JD.Second-Business","")

errors<- double(4)
conf.matrix<- list('1' = data.frame(c(0,0), c(0,0)), '2' = data.frame(c(0,0), c(0,0)),
                   '3' = data.frame(c(0,0), c(0,0)), '4' = data.frame(c(0,0), c(0,0)))
auc<- double(4)
colours <- c("red","green","blue", "pink")
        
for(i in 1:4){
        if(vars.excl[i] %in% ""){
              formula<- "b.rpdol~.- mlsto - return.pdol-Year - code.contact - code.client"  
        } else{
        formula<- paste("b.rpdol~.- mlsto - return.pdol-Year-code.client - code.contact",
                        "-", vars.excl[i], sep=" ")
        }
        
        fit<-gbm(as.formula(formula), 
                 data=train, distribution="bernoulli", n.trees=5000,
                 shrinkage=0.001,
                 interaction.depth=3)
        pred<- predict(fit, test, n.tree=5000, type="response")
        errors[i]<- sum(temp)/nrow(test)
        
        #pROC
        pred.p<- roc(test$b.rpdol, pred)
        
        if(i==1){
                plot.roc(pred.p, col= colours[i], print.thres=T)
                
        } else{
                plot.roc(pred.p, col= colours[i], add=TRUE, print.thres=T)
        }
        
        auc[i]<- auc(pred.p)
        
        #confusion matrix
        conf.mat<- coords(pred.p, "best")
        pred1<- ifelse(pred>= conf.mat[1], 1, 0)
        temp2<- data.frame('pred1' = pred1, 'ans' = test$b.rpdol)
        conf.matrix[[i]] = as.data.frame.matrix(table(temp2$pred1, temp2$ans))
        cat(i," ")
}

conf.matrix
auc

#create new data frame 'shrink' to place trees and errors vectors together, then plot:
shrink<- data.frame("shrinkage"=shrink.seq, "auc" = auc[1:4])
ggplot(shrink, aes(x=shrinkage, y= auc)) + geom_line() + geom_point()+ geom_line()

#best to not have JD.Second OR Business!!!  :(
```

Tune shrinkage value:
```{r, echo=FALSE}

formula<- "b.rpdol~.- mlsto - return.pdol-Year-code.client - code.contact-JD.Second - Business"

errors<- double(4)
shrink.seq<-c(0.0005, .001,.005, 0.01)
conf.matrix<- list('1' = data.frame(c(0,0), c(0,0)), '2' = data.frame(c(0,0), c(0,0)),
                   '3' = data.frame(c(0,0), c(0,0)), '4' = data.frame(c(0,0), c(0,0)))
auc<- double(4)
colours <- c("red", "yellow", "green", "blue")
        
for(i in 1:4){
        fit<-gbm(as.formula(formula), 
                 data=train, distribution="bernoulli", n.trees=5000,
                 shrinkage=shrink.seq[i],interaction.depth=3)
        pred<- predict(fit, test, n.tree=5000, type="response")
        errors[i]<- sum(temp)/nrow(test)
        
        #pROC
        pred.p<- roc(test$b.rpdol, pred)
        
        if(i==1){
                plot.roc(pred.p, col= colours[i], print.thres=T)
                
        } else{
                plot.roc(pred.p, col= colours[i], add=TRUE, print.thres=T)
        }
        
        auc[i]<- auc(pred.p)
        
        #confusion matrix
        conf.mat<- coords(pred.p, "best")
        pred1<- ifelse(pred>= conf.mat[1], 1, 0)
        temp2<- data.frame('pred1' = pred1, 'ans' = test$b.rpdol)
        conf.matrix[[i]] = as.data.frame.matrix(table(temp2$pred1, temp2$ans))
        cat(i," ")
}

conf.matrix
auc

#create new data frame 'shrink' to place trees and errors vectors together, then plot:
shrink<- data.frame("shrinkage"=shrink.seq, "auc" = auc[1:4])
ggplot(shrink, aes(x=shrinkage, y= auc)) + geom_line() + geom_point()+ geom_line()

#best case auc = 0.756 with shrinkage = 0.001

```

```{r, echo=FALSE}


#shrinkage should be 0.001, now find number of trees

ntree.seq<-c(2000,3000,4000,6000,8000)
conf.matrix<- list('1' = data.frame(c(0,0), c(0,0)), '2' = data.frame(c(0,0), c(0,0)),
                   '3' = data.frame(c(0,0), c(0,0)), '4' = data.frame(c(0,0), c(0,0)),
                   '5' = data.frame(c(0,0), c(0,0)))
auc<- double(5)
colours <- c("red", "yellow", "green", "blue", "purple")

for(i in 1:5){
        fit<-gbm(as.formula(formula), 
                 data=train, distribution="bernoulli", n.trees= ntree.seq[i],
                 shrinkage=0.001,interaction.depth=3)
        pred<- predict(fit, test, n.tree=ntree.seq[i], type="response")
        errors[i]<- sum(temp)/nrow(test)
        
        #pROC
        pred.p<- roc(test$b.rpdol, pred)
        
        if(i==1){
                plot.roc(pred.p, col= colours[i], print.thres=T)
                
        } else{
                plot.roc(pred.p, col= colours[i], add=TRUE, print.thres=T)
        }
        
        auc[i]<- auc(pred.p)
        
        #confusion matrix
        conf.mat<- coords(pred.p, "best")
        pred1<- ifelse(pred>= conf.mat[1], 1, 0)
        temp2<- data.frame('pred' = pred1, 'ans' = test$b.rpdol)
        conf.matrix[[i]] = as.data.frame.matrix(table(temp2$pred, temp2$ans))
        cat(i," ")
}

conf.matrix
auc

#create new data frame 'shrink' to place trees and errors vectors together, then plot:
shrink<- data.frame("shrinkage"=ntree.seq, "auc" = auc[1:5])
ggplot(shrink, aes(x=shrinkage, y=auc)) + geom_line() + geom_point()+ geom_line()

#6000 trees seems best?

#----------------------------------------------------------------------

#shrinkage should be 0.001, 4000 trees, now find interaction.depth

int.seq<-c(1,2,3,4,6)
conf.matrix<- list('1' = data.frame(c(0,0), c(0,0)), '2' = data.frame(c(0,0), c(0,0)),
                   '3' = data.frame(c(0,0), c(0,0)), '4' = data.frame(c(0,0), c(0,0)),
                   '5' = data.frame(c(0,0), c(0,0)))
auc<- double(5)
colours <- c("red", "yellow", "green", "blue", "purple")

for(i in 1:5){
        fit<-gbm(as.formula(formula), 
                 data=train, distribution="bernoulli", n.trees= 6000,
                 shrinkage=0.001,interaction.depth=int.seq[i])
        pred<- predict(fit, test, n.tree=6000, type="response")
        
        #pROC
        pred.p<- roc(test$b.rpdol, pred)
        
        if(i==1){
                plot.roc(pred.p, col= colours[i], print.thres=T)
                
        } else{
                plot.roc(pred.p, col= colours[i], add=TRUE, print.thres=T)
        }
        
        auc[i]<- auc(pred.p)
        
        #confusion matrix
        conf.mat<- coords(pred.p, "best")
        pred1<- ifelse(pred>= conf.mat[1], 1, 0)
        temp2<- data.frame('pred' = pred1, 'ans' = test$b.rpdol)
        conf.matrix[[i]] = as.data.frame.matrix(table(temp2$pred, temp2$ans))
        cat(i," ")
}

conf.matrix
auc

#create new data frame 'shrink' to place trees and errors vectors together, then plot:
shrink<- data.frame("shrinkage"=int.seq, "auc" = auc[1:5])
ggplot(shrink, aes(x=shrinkage, y=auc)) + geom_line() + geom_point()+ geom_line()

## use interaction.depth = 3



#------------------------------------------------
# now tune min obs in node

obs.seq<-c(10,20,40,50)
conf.matrix<- list('1' = data.frame(c(0,0), c(0,0)), '2' = data.frame(c(0,0), c(0,0)),
                   '3' = data.frame(c(0,0), c(0,0)), '4' = data.frame(c(0,0), c(0,0)))
auc<- double(4)
colours <- c("red", "yellow", "green", "blue")

for(i in 1:4){
        fit<-gbm(as.formula(formula), 
                 data=train, distribution="bernoulli", n.trees= 6000,
                 shrinkage=0.001,interaction.depth=3,
                 n.minobsinnode = obs.seq[i])
        pred<- predict(fit, test, n.tree=6000, type="response")

        #pROC
        pred.p<- roc(test$b.rpdol, pred)
        
        if(i==1){
                plot.roc(pred.p, col= colours[i], print.thres = T)
                
        } else{
                plot.roc(pred.p, col= colours[i], add=TRUE , print.thres = T)
        }
        
        auc[i]<- auc(pred.p)
        
        #confusion matrix
        conf.mat<- coords(pred.p, "best")
        pred1<- ifelse(pred>= conf.mat[1], 1, 0)
        temp2<- data.frame('pred' = pred1, 'ans' = test$b.rpdol)
        conf.matrix[[i]] = as.data.frame.matrix(table(temp2$pred, temp2$ans))
        cat(i," ")
}

conf.matrix
auc

#create new data frame 'shrink' to place trees and errors vectors together, then plot:
shrink<- data.frame("shrinkage"=obs.seq, "auc" = auc[1:4])
ggplot(shrink, aes(x=shrinkage, y=auc)) + geom_line() + geom_point()+ geom_line()

#go with 10????!

```

So paramters are .... 

    * shrinkage = 0.001
    * exclude vars = JD.Second, Business, code.client, Year, code.contact
    * n.trees = 4000
    * interaction.depth = 3
    * minobsinnode = 10
    
to obtain AUC = 0.785

Can we change timespan to discretised without affecting AUC??


```{r, echo=FALSE}

formula<- "b.rpdol~.- mlsto - return.pdol-Year-code.client - code.contact-JD.Second - Business - timespan.cbrt"

conf.matrix<- list('1' = data.frame(c(0,0), c(0,0)), '2' = data.frame(c(0,0), c(0,0)),
                   '3' = data.frame(c(0,0), c(0,0)), '4' = data.frame(c(0,0), c(0,0)))
auc<- double(4)
colours <- c("red", "yellow", "green", "blue")
timeclust.seq<- c(4:7)

x<- dist(all9a$timespan.cbrt, method = 'euclidean')
h.fit<- hclust(x, method = 'ward.D2')

for(i in 1:4){
        #create timespan cluster number column
        all9a$b.timespan.cbrt<- as.factor(cutree(h.fit, k= timeclust.seq[i]))
        
        set.seed(300)
        sample<- sample(1:nrow(all9a), 2/3*nrow(all9a), replace=F)
        train<- all9a[sample,]
        test<- all9a[-sample,]
        
        fit<-gbm(as.formula(formula), 
                 data=train, distribution="bernoulli", n.trees= 4000,
                 shrinkage=0.001,interaction.depth=3,
                 n.minobsinnode = 10)
        pred<- predict(fit, test, n.tree=4000, type="response")

        #pROC
        pred.p<- roc(test$b.rpdol, pred)
        
        if(i==1){
                plot.roc(pred.p, col= colours[i], print.thres = T)
                
        } else{
                plot.roc(pred.p, col= colours[i], add=TRUE , print.thres = T)
        }
        
        auc[i]<- auc(pred.p)
        
        #confusion matrix
        conf.mat<- coords(pred.p, "best")
        pred1<- ifelse(pred>= conf.mat[1], 1, 0)
        temp2<- data.frame('pred' = pred1, 'ans' = test$b.rpdol)
        conf.matrix[[i]] = as.data.frame.matrix(table(temp2$pred, temp2$ans))
        cat(i," ")
}

conf.matrix
auc

#create new data frame 'shrink' to place trees and errors vectors together, then plot:
shrink<- data.frame("shrinkage"= timeclust.seq, "auc" = auc[1:4])
ggplot(shrink, aes(x=shrinkage, y=auc)) + geom_line() + geom_point()+ geom_line()

#takes it down to 0.781 with 5 clusters, not too bad for the ability to use timespan clusters.
#takes it down to 0.783 with 6 clusters

```

6 timespan clusters seems to give quite good performance :) 0.783. Lets see what those clusters are:

```{r, echo=FALSE}

#timespan.cbrt
first.vec<- all9a$timespan.cbrt
x<- dist(first.vec, method = 'euclidean')
fit<- hclust(x, method = 'ward.D2')
plot(fit)
k.choose=6
rect.hclust(fit, k = k.choose)

#assign a cluster number to all rows in data frame
all9a$b.timespan.cbrt<- as.factor(cutree(fit, k= k.choose))

for(i in 1:k.choose){
        print(
        summary(all9a %>% select(b.timespan.cbrt, timespan.cbrt) %>% 
                        filter(b.timespan.cbrt ==i))
        )
}

#clusters roughly break down to 1 day, 3 wks, 2.5m, 9m, 1.5yr, 3 yr, over 3 yr
# in cbrt days this is equivalent to breaks of 0,1,2,7589, 4.2358, 6.5, 8.183, 10.307, 14.1
#make new clusters:
all9a$b.timespan.cbrt<- cut(all9a$timespan.cbrt, 
                            breaks= c(0,2.7589, 4.2358, 6.5, 8.183, 10.307, 14.1), 
                            include.lowest=TRUE, 
                            labels= c("1d-3wk","3wk-2.5m", "2.5m-9m","9m-1.5y","1.5y-3y",">3y"))

set.seed(300)
sample<- sample(1:nrow(all9a), 2/3*nrow(all9a), replace=F)
train<- all9a[sample,]
test<- all9a[-sample,]

fit<-gbm(as.formula(formula), 
        data=train, distribution="bernoulli", n.trees= 4000,
        shrinkage=0.001,interaction.depth=3,
        n.minobsinnode = 10)
pred<- predict(fit, test, n.tree=4000, type="response")

#pROC
pred.p<- roc(test$b.rpdol, pred)
plot.roc(pred.p, col= "pink", print.thres = T)
auc(pred.p)

#reduces AUC to 0.780 :(
#go through tuning process again?

all9a<- all9a %>% select(-timespan.cbrt)
```



But can we improve the AUC by bringing back some of the missing variables in a smart way?? 

For example, bring back code.client, but only if clients have more than say 10 jobs?

```{r, echo=FALSE}

#new variable for clients with more than 10 jobs
#list of clients with more than 10 jobs
all9b<- all9a
client.count<- ddply(all9b, .(code.client), nrow)
client.count<- arrange(client.count, -V1)

client.count2<- client.count[client.count$V1>20 & !is.na(client.count$code.client),]

all9b$code.client<- as.character(all9b$code.client)
all9b$reduc.client<- ifelse(all9b$code.client %in% client.count2$code.client,
                            all9b$code.client,
                            NA)
all9b$code.client<- as.factor(all9b$code.client)
all9b$reduc.client<- as.factor(all9b$reduc.client)

#see if ROC improves

formula<- "b.rpdol~.- mlsto - return.pdol-Year-code.client - code.contact-JD.Second - Business"

client.lim <- c(20,30,40,60,70)
conf.matrix<- list('1' = data.frame(c(0,0), c(0,0)), '2' = data.frame(c(0,0), c(0,0)),
                   '3' = data.frame(c(0,0), c(0,0)), '4' = data.frame(c(0,0), c(0,0)),
                   '5' = data.frame(c(0,0), c(0,0)))
auc<- double(5)
colours <- c("red", "yellow", "green", "blue", "purple")

for(i in 1:5){
        
        client.count2<- client.count[client.count$V1> client.lim[i] &
                                             !is.na(client.count$code.client),]
        all9b$code.client<- as.character(all9b$code.client)
        all9b$reduc.client<- ifelse(all9b$code.client %in% client.count2$code.client,
                            all9b$code.client,
                            NA)
        all9b$code.client<- as.factor(all9b$code.client)
        all9b$reduc.client<- as.factor(all9b$reduc.client)

        #see if ROC improves

        #redo train and test
        set.seed = 200
        sample<- sample(1:nrow(all9a), 2/3*nrow(all9a), replace=F)
        train<- all9a[sample,]
        test<- all9a[-sample,]
        
        #make boosted tree
        fit<-gbm(as.formula(formula), 
                 data=train, distribution="bernoulli", n.trees= 4000,
                 shrinkage=0.001,interaction.depth=3,
                 n.minobsinnode = 10)
        pred<- predict(fit, test, n.tree=4000, type="response")

        #pROC
        pred.p<- roc(test$b.rpdol, pred)
        
        if(i==1){
                plot.roc(pred.p, col= colours[i], print.thres = T)
                
        } else{
                plot.roc(pred.p, col= colours[i], add=TRUE , print.thres = T)
        }
        
        auc[i]<- auc(pred.p)
        
        #confusion matrix
        conf.mat<- coords(pred.p, "best")
        pred1<- ifelse(pred>= conf.mat[1], 1, 0)
        temp2<- data.frame('pred' = pred1, 'ans' = test$b.rpdol)
        conf.matrix[[i]] = as.data.frame.matrix(table(temp2$pred, temp2$ans))
        cat(i," ")
        
}

conf.matrix
auc

#create new data frame 'shrink' to place trees and errors vectors together, then plot:
shrink<- data.frame("shrinkage"=client.lim, "auc" = auc[1:5])
ggplot(shrink, aes(x=shrinkage, y=auc)) + geom_line() + geom_point()+ geom_line()

#best I can do is 0.783
```

Make a function to do the same with code.contact, JD.Second, and Business????




    
    
    
    
    
    