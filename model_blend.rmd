---
title: "Model Averaging"
author: "Amy Cook"
date: "May 26, 2016"
output: word_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)

library("plyr")
library("dplyr")
library('tidyr')
library('magrittr')
library('reshape2')
library('ggplot2')
library('gbm')
library('caret')
library('pROC')
library('e1071')
library('randomForest')
library('party')

setwd("C:/Users/n9232371/Documents/Consultbusiness/data")

if(.Platform$OS.type == 'windows'){
        all10mice = read.csv('C:/Users/n9232371/OneDrive/shared files/Bligh Tanner/masters/data/all10mice_May16.csv')
        source("C:/Users/n9232371/Documents/github/consult/functions.R")
} else{
        all10mice = read.csv('~/OneDrive/shared files/Bligh Tanner/masters/data/all10mice_May16.csv')
        source("/Users/yam/Documents/github/consult/functions.R")

}


```

Model averaging how to do it>?
Best models are ..

* boosted tree
* logisitic regression
* random forest

# For each method, create a complete dataset of predictions created from ten fold cross validation
```{r}

## new variables for FWLS and methods
# create f.rpdol
all10mice$f.rpdol <- as.factor(all10mice$b.rpdol)
levels(all10mice$f.rpdol)[levels(all10mice$f.rpdol) == "0"] <- "profit"
levels(all10mice$f.rpdol)[levels(all10mice$f.rpdol) == "1"] <- "loss"

#perform 10-fold cross validation on train set to create complete train set of predictions for each method
full.predict <- function(df = all10mice, method = "log", x.folds = 5, manual.seed = 100){
        
        #set up 10 fold cv using caret function
        set.seed(manual.seed)
        folds <- createFolds(df$f.rpdol, k = x.folds, list = T, returnTrain = F)
        #now have folds[[1]] through folds[[10]] list of rows to exclude
        
        #create NULL dataframe with row names from folds
        method.pred <- data.frame('rownames' = unlist(folds))
        temp.pred = NULL
        
        
        #define formula
        if(method %in% c('log','rf')){
                formula <-"f.rpdol ~ Discipline + pc.pro + b.timespan.cbrt + no.users + b.inv.log + client.totinv.log + Business + majority.pos + pc.majpos.log + JD.Second + Billing.Type"
        } 
        
        if(method == 'boost') {
                #no JD.Second
                formula <-"b.rpdol ~ Discipline + pc.pro + b.timespan.cbrt + no.users + b.inv.log + client.totinv.log + Business + majority.pos + pc.majpos.log"
        }
        
        #loop over each fold, and compile predictions
        for (j in 1:length(folds)) {
                
                #turn predictors and response into 'ordered' variables for roc() to work
                test<- df[folds[[j]],]
                levels(test$f.rpdol) <- c('profit', 'loss')
                test$f.rpdol <- ordered(test$f.rpdol)
                        
                if(method %in% 'rf'){
                        fit <- randomForest(as.formula(formula), data = df[-folds[[j]],], 
                                    mtry = 4, ntree = 1000)
                        pred <- predict(fit, test, type = "prob")
                        pred <- pred[,2]
                        
                }
                
                if(method %in% 'log'){
                        fit<- glm(as.formula(formula), 
                                  data = df[-folds[[j]],], family = binomial())
                        pred <- predict(fit, test,
                                        type = "response")
                } 
                if(method %in% 'boost'){
                        fit <- gbm(as.formula(formula), data = df[-folds[[j]],],
                                   distribution = "bernoulli", n.trees = 10000,
                                   shrinkage = 0.001, interaction.depth = 5,
                                   n.minobsinnode = 20)
                        
                        pred <- predict(fit, test, n.tree = 10000, type = "response")
                }
                
                        
                temp.pred <- c(temp.pred, pred)
                        
                #print j value
                cat(j, " ")
                
        }
        
        method.pred[, method] = temp.pred
        return(method.pred)
        
}


pred.log = full.predict(df = all10mice, method = 'log', x.folds = 5, manual.seed = 100)
pred.rf = full.predict(df = all10mice, method = 'rf', x.folds = 5, manual.seed = 100)
pred.boost = full.predict(df = all10mice, method = 'boost', x.folds = 5, manual.seed = 100)

#merge all by rownames
pred.full = Reduce(full_join, list(pred.log, pred.rf, pred.boost))
gather.pred = gather(pred.full, key = method, value = pred.val,
                     -rownames)
order.rows = gather.pred %>% group_by(rownames) %>% 
        summarise(mean = mean(pred.val)) %>%
        arrange(mean) %>% ungroup
gather.pred$rownames <- factor(gather.pred$rownames,
                               levels= order.rows$rownames)


#plot spread of predictions

ggplot(gather.pred, aes(x = rownames, y = pred.val, group = method)) + geom_point(aes(colour = method)) +
        geom_line(aes(colour = method))

ggplot(gather.pred, aes(x = method, y = pred.val)) + geom_boxplot(aes(fill = method), colour = "darkgray")

#randomForest seems to predict a bit higher than the other two methods. should I standardise it a bit??

```

Now create complete train set

```{r}

all10.blend = full_join(all10mice %>% mutate(rown = 1:nrow(all10mice)), pred.full, 
                        by = c('rown'='rownames'))
all10.blend <- all10.blend %>% select(-rown)

# need to normalise method responses
ggplot(all10.blend, aes(x= sign(log) * abs(log)^(1/3))) + geom_histogram()
ggplot(all10.blend, aes(x= rf^0.5)) + geom_histogram()
ggplot(all10.blend, aes(x= log(boost))) + geom_histogram()

#cube root of log
all10.blend = mutate(all10.blend, norm.log = sign(log) * abs(log)^(1/3))
all10.blend = mutate(all10.blend, norm.rf = rf^0.5)
all10.blend = mutate(all10.blend, norm.boost = log(boost))

write.csv(all10.blend, '~/OneDrive/shared files/Bligh Tanner/masters/data/all10blend.csv')

ggplot(all10.blend, aes(x= norm.log)) + geom_histogram()

#create test and train set: 0.75/0.25
set.seed(100)
train = sample_frac(all10.blend, 0.75, replace = FALSE)
test = setdiff(all10.blend, train)

```


# Try Feature weighted linear stacking

```{r cars}
#first write formula

formula.log <- "f.rpdol ~ Discipline + pc.pro + b.timespan.cbrt + no.users + b.inv.log + client.totinv.log + Business + majority.pos + pc.majpos.log + JD.Second + Billing.Type + norm.log + norm.rf + norm.boost"

formula.rf <- "f.rpdol ~ Discipline + pc.pro + b.timespan.cbrt + no.users + b.inv.log + client.totinv.log + Business + majority.pos + pc.majpos.log + JD.Second + Billing.Type + norm.log + norm.rf + norm.boost"

formula.boost <- "b.rpdol ~ Discipline + pc.pro + b.timespan.cbrt + no.users + b.inv.log + client.totinv.log + Business + majority.pos + pc.majpos.log + Billing.Type + norm.log + norm.rf + norm.boost + JD.Second"

#formula to add interaction terms for logistic regression
metafeatures = strsplit(formula.log, split = c("\\s\\~\\s|\\s\\+\\s"))[[1]]
methods = metafeatures[13:15]
metafeatures = metafeatures[2:12]

for(j in seq_along(methods)){
        for(m in seq_along(metafeatures)){
                formula.log <- paste(formula.log, " + ", metafeatures[m], "*", methods[j], sep = "")
        }
}
#add terms to allow for constants [@Sill2009] - already done as everything is included as a single variable without interaction

#run linear regression
find.auc <- function(method = "log") {
        
        if (method == "log") {
                fit <- glm(as.formula(formula.log),
                               data = train,
                               family = binomial())
                
                pred <- predict(fit, test, type = "response")
                
                formula.check = "f.rpdol ~ Discipline + pc.pro + b.timespan.cbrt + no.users + b.inv.log + client.totinv.log + Business + majority.pos + pc.majpos.log + JD.Second + Billing.Type"
                
                check.fit <- glm(as.formula(formula.check),
                               data = train,
                               family = binomial())
                
                pred.c <- predict(check.fit, test, type = "response")
        }
        
        if (method == "rf") {
        fit <- randomForest( as.formula(formula.rf), data = train,
                mtry = 4, ntree = 1000, importance = TRUE
                )
        pred <- predict(fit, test, type = "prob")
        pred <- pred[, 2]
        
        formula.check = "f.rpdol ~ Discipline + pc.pro + b.timespan.cbrt + no.users + b.inv.log + client.totinv.log + Business + majority.pos + pc.majpos.log + JD.Second + Billing.Type"
        
        check.fit <- randomForest( as.formula(formula.check), data = train,
                mtry = 4, ntree = 1000
                )
        pred.c <- predict(check.fit, test, type = "prob")
        pred.c <- pred.c[, 2]
        }
        
        if (method == "boost") {
                fit <- gbm(as.formula(formula.boost), data = train,
                                   distribution = "bernoulli", n.trees = 6000,
                                   shrinkage = 0.0005, interaction.depth = 3,
                                   n.minobsinnode = 40)
                                
                pred <- predict(fit, test, n.tree = 6000, type = "response")
        
                formula.check = "b.rpdol ~ Discipline + pc.pro + b.timespan.cbrt + no.users + b.inv.log + client.totinv.log + Business + majority.pos + pc.majpos.log + Billing.Type"
        
                check.fit <- gbm(as.formula(formula.check), data = train,
                        distribution = "bernoulli", n.trees = 10000,
                        shrinkage = 0.001, interaction.depth = 5,
                        n.minobsinnode = 20)
                pred.c <- predict(check.fit, test, n.tree = 6000, type = "response")
        }
        
        #assign fit to global
        assign("fit", fit, envir = .GlobalEnv)
        saveRDS(fit, paste("/Users/yam/Documents/github/consult/finalwriteup/report_data/",
                           method,"blend.rds", sep = ""))
        
        #pROC
        pred.p <- pROC::roc(test$f.rpdol, pred)
        
        pROC::plot.roc(pred.p, col = "red", print.thres = F)
        
        print(pROC::auc(pred.p))
        
        #print check
        pred.pc <- pROC::roc(test$f.rpdol, pred.c)
        pROC::plot.roc(pred.pc, col = "blue", add = TRUE , print.thres = F)
        
        #print AUC's
        print(
                c("blend" = pROC::auc(pred.p), "check" = pROC::auc(pred.pc))
        )
        
}

find.auc(method = "log")
#function saves model as 'fit'
summary(fit)
#not many of the interactions had significant relationships

```


# Try random forest

```{r pressure, echo=FALSE}

#use caret to tune 
caret.all(method = "rf", df = train, formula = formula.rf, sample.frac = 0.75, seed = 100)


find.auc(method = "rf")
importance(fit, type = 1) #permutation importance
#indicates norm.log is more important

```

# Try boosted trees
```{r pressure, echo=FALSE}
#tune parameters

# shrinkage = 0.0005
# n.trees = 6000
# interaction.depth = 3
# n.minobsinnode = 40

find.auc(method = "boost")
summary(fit)
saveRDS(summary(fit), paste("/Users/yam/Documents/github/consult/finalwriteup/report_data/",
                           method,"blend.rds", sep = ""))
# norm.log was by far the most important.

```

Hm none of the blends are doing better than models alone.
Try comparing how similar the predictions are

```{r}

#plain model averaging

#how to normalise the prediction variables
all10.blend = mutate(all10.blend, model.av = (log + rf +boost)/3) 

pred.p <- pROC::roc(all10.blend$f.rpdol, all10.blend$model.av)
        
pROC::plot.roc(pred.p, col = "red", print.thres = F)
pROC::plot.roc(pred.p, col = "blue", print.thres = F, add = T)

#hmm model averaging actually makes a bit of an improvement, weird.

# what about boosted tree with only 3 variables?
# or log regression wiht only 3 variables?

```

Variable importance from cforest
```{r}

cfor.plotsave(df= all10.blend, name= 'cfor_blend', formular = formula.rf)

```


20 runs of each method. compare against logistic regression
8 variables have been selected via variable importance analysis


```{r}

formula.log <- "f.rpdol ~ b.timespan.cbrt + no.users + b.inv.log + Business + JD.Second + norm.log + norm.rf + norm.boost"

formula.rf <- "f.rpdol ~ b.timespan.cbrt + no.users + b.inv.log + Business + JD.Second + norm.log + norm.rf + norm.boost"

formula.boost <- "b.rpdol ~ b.timespan.cbrt + no.users + b.inv.log + Business + JD.Second + norm.log + norm.rf + norm.boost"

formula.sboost <- "b.rpdol ~ norm.log + norm.rf + norm.boost"

#formula to add interaction terms for logistic regression
metafeatures = strsplit(formula.log, split = c("\\s\\~\\s|\\s\\+\\s"))[[1]]
methods = metafeatures[7:9]
metafeatures = metafeatures[2:6]

for(j in seq_along(methods)){
        for(m in seq_along(metafeatures)){
                formula.log <- paste(formula.log, " + ", metafeatures[m], "*", methods[j], sep = "")
        }
}

# tune boosted trees and rf
caret.all(df = train, formula = formula.rf, sample.frac = 0.75, seed = 100)
#mtry = 3
caret.all(df = train, formula = formula.sboost, sample.frac = 0.75, seed = 100)
# interaction.depth = 6, nminobs = 10, shrink = 0.0005, trees = 6000
caret.all(df = train, formula = formula.boost, sample.frac = 0.75, seed = 100)
# interaction.depth = , nminobs = , shrink = 0.0005, trees = 6000


iter.auc <- function(mult = 4, x.folds = 5, 
                     methods = c("orig.log","log","rf","boost","average",
                                 "simp.log","simp.boost"),
                     seedy = 100, df = all10.blend) {
        
        #create test and train set: 0.75/0.25
        set.seed(seedy)
        auc <- rep(list(rep(0, mult*x.folds)), length(methods))
        names(auc) = methods
        
        #create model averaged column
        df = mutate(df, model.av = (log + rf +boost)/3) 
        
        #set up 10 fold cv using caret function
        folds <- createFolds(df$f.rpdol, k = x.folds, list = T, returnTrain = F)
        #now have folds[[1]] through folds[[10]] list of rows to exclude
        if(mult > 1){
                for(k in 2:mult){                                
                    set.seed(sample(1:1000,1))
                    folds.temp = createFolds(df$f.rpdol, k = x.folds, list = T, returnTrain=F)
                    folds = append(folds, folds.temp)
                }
        }
        
        for(i in seq_along(folds)){
                
        train = df[-folds[[i]],]
        test = df[folds[[i]],]

        if ("log" %in% methods) {
                print("log")
                fit <- glm(as.formula(formula.log),
                               data = train,
                               family = binomial())
                
                pred <- predict(fit, test, type = "response")
                auc[["log"]][i] <- pROC::roc(test$f.rpdol, pred) %>% auc() %>% round(3)
        }
        
        if ("simp.log" %in% methods) {
                print("simp.log")
                fit <- glm(f.rpdol ~ norm.log + norm.rf + norm.boost,
                               data = train,
                               family = binomial())
                
                pred <- predict(fit, test, type = "response")
                auc[["simp.log"]][i] <- pROC::roc(test$f.rpdol, pred) %>% auc() %>% round(3)
        }
        
        if ("rf" %in% methods) {
                print("rf")
        fit <- randomForest( as.formula(formula.rf), data = train,
                mtry = 3, ntree = 1000, importance = TRUE
                )
        pred <- predict(fit, test, type = "prob")
        pred <- pred[, 2]
        
        auc[["rf"]][i] <- pROC::roc(test$f.rpdol, pred) %>% auc() %>% round(3)

        }
        
        if ("simp.boost" %in% methods) {
                print("simp.boost")
                fit <- gbm(b.rpdol ~ norm.log + norm.rf + norm.boost, data = train,
                                   distribution = "bernoulli", n.trees = 6000,
                                   shrinkage = 0.0005, interaction.depth = 6,
                                   n.minobsinnode = 10)
                pred <- predict(fit, test, n.tree = 6000, type = "response")
                auc[["simp.boost"]][i] <- pROC::roc(test$f.rpdol, pred) %>% auc() %>% round(3)

        }
        
        if ("boost" %in% methods) {
                print("boost")
                fit <- gbm(as.formula(formula.boost), data = train,
                                   distribution = "bernoulli", n.trees = 6000,
                                   shrinkage = 0.0005, interaction.depth = 3,
                                   n.minobsinnode = 10)
                pred <- predict(fit, test, n.tree = 6000, type = "response")
                auc[["boost"]][i] <- pROC::roc(test$f.rpdol, pred) %>% auc() %>% round(3)

        }
        
        if ("orig.log" %in% methods) {
                print("orig.log")
                pred <- test$log
                auc[["orig.log"]][i] <- pROC::roc(test$f.rpdol, pred) %>% auc() %>% round(3)

        }
        
        if ("average" %in% methods) {
                print("average")
                pred <- test$model.av
                auc[["average"]][i] <- pROC::roc(test$f.rpdol, pred) %>% auc() %>% round(3)
        }
        
        
        #print AUC's
        cat(i, " ")
        
        }
        #assign fit to global
        assign("auc.list", auc, envir = .GlobalEnv)
        # saveRDS(auc, paste("/Users/yam/Documents/github/consult/finalwriteup/report_data/",
        #                    "auc_blend_20.rds", sep = ""))
        
}

iter.auc(mult = 10, x.folds = 10, seedy = 100, df = all10.blend,
         methods = c("orig.log","log","average", "boost","rf", "simp.log","simp.boost"))

auc.list
saveRDS(auc.list, "/Users/yam/Documents/github/consult/finalwriteup/report_data/blend_auc.rds")

ggplot(melt(auc.list), aes(x= factor(L1), y= value)) + 
        geom_violin(aes(fill = L1, colour = L1)) + 
        geom_jitter(alpha = 0.2, shape = 16, colour= 'gray70') +
        stat_summary(fun.y="mean", geom="point", colour = "gray60", shape =3) +
        labs(x = "Method", y = "Area Under Curve (AUC)",
             title = "AUC Distribution from 20 models of each Method") +
        scale_x_discrete(labels = c("boost" = "Boosted Trees", 
                         "log" = "Logistic Regression", "average" = "Simple Average",
                         "orig.log" = "Orignal LogReg", "rf" = "Random Forest"))
```



