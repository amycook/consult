---
title: "Variable Selection"
author: "Amy Cook"
date: "Thursday, June 18, 2015"
output: word_document
---


```{r, echo=FALSE, include=FALSE}

library('knitr', lib = 'C:/Progra~1/R/R-3.2.1/library')
library('ggplot2', lib = 'C:/Progra~1/R/R-3.2.1/library')
library("plyr",lib = 'C:/Progra~1/R/R-3.2.1/library')
library("dplyr",lib = 'C:/Progra~1/R/R-3.2.1/library')
library('magrittr',lib='C:/Progra~1/R/R-3.2.1/library')
library('reshape2',lib='C:/Progra~1/R/R-3.2.1/library')
library("rpart",lib = 'C:/Program Files/R/R-3.2.1/library')
library('car', lib = 'C:/Progra~1/R/R-3.2.1/library')
library('e1071', lib = 'C:/Progra~1/R/R-3.2.1/library')
library('corrgram', lib = 'C:/Progra~1/R/R-3.2.1/library')
library('party', lib = 'C:/Progra~1/R/R-3.2.1/library')
library('randomForest', lib = 'C:/Progra~1/R/R-3.2.1/library')
library('RColorBrewer',lib='C:/Progra~1/R/R-3.2.1/library')

# library('knitr')
# library('ggplot2')
# library("dplyr")
# library("plyr")
# library('magrittr')
# library('reshape2')
# library("rpart")
# library('car')
# library('e1071')
# library('corrgram')
# library('party')
# 
# setwd("~/OneDrive/shared files/Bligh Tanner/masters/data")
# setwd("C:/Users/n9232371/Documents/Consultbusiness/data")
opts_knit$set(root.dir= "~/OneDrive/shared files/Bligh Tanner/masters/data")
```



```{r load_data, echo=FALSE}
all7<- read.csv('all7.csv')[,-1]
all7$Start.Date<- as.Date(all7$Start.Date)
```

Check for normality of return variable return per dollar
Outliers were deleted first

```{r}
# try deleting very high return.pdol values greater than 3
test<- all7 %>% filter(return.pdol <=3 & return.pdol> -2)
qqPlot(test$return.pdol)
qqPlot(log(test$return.pdol+.97))
#have a look at the shape of return.pdol as bar graph
ggplot(test, aes(x=return.pdol)) + geom_histogram(aes(y=..density..), binwidth=.1)
ggplot(test, aes(x=log(test$return.pdol+.97))) + geom_histogram(aes(y=..density..), binwidth=.1)
```

definietly don't want to use log - worse.
Let's look at standard deviation, mean, median, skewness, kurtosis
```{r}
sd(test$return.pdol)
mean(test$return.pdol)
median(test$return.pdol)
#mode
names(sort(-table(test$return.pdol)))[1]
skewness(test$return.pdol)
skewness(log(test$return.pdol+.97))
kurtosis(test$return.pdol)
```


skewness only 0.92!! for unlogged
skewness is -2.6 for logged data

kurtosis equals 2.85 - very peakedy - ie not flat. normal distribution is 0.

Create new data set that has outliers deleted, all7a

```{r}

### delete outliers! and variables that aren't by milestone
all7a<- all7 %>% filter(return.pdol <=3 & return.pdol> -2)
all7a<- all7 %>% select(-Paperless,-Innovation, -JobInvCount,-job.first.inv.email.Sent, 
                        -Total.Costs..AUD., -Stage, -Folders, -Total.Fee, -Disburse, -Subcon.fee,
                        -Job.Size, -Tot.Invoiced, -charge, -cost, -Dis.subcon, -hours,-profit,-balance,
                        -Role)

# write.csv(all7a,'all7a.csv')
all7a<- read.csv('all7a.csv')[,-1]
```

# Variable Selection

It would be good to be able to narrow down the variables to the correlated or strongly affecting ones. This improves accuracy and speed of the final machine learning algoriths.

Anova and Linear regression will give us an idea of variable importance. Look at coefficients

In order to get Anova and linear regression to work on this data set, start with the variables that are complete or almost complete. Then can add additional variables one by one. The function below does this automatically. 

For lm, the output is ordered from abs(highest coefficient)

```{r, echo=FALSE}
BT.lin<- function(type= 'lm', data= all7a, add.var = 'Job.Type.Primary') {
        formula = paste("return.pdol ~ inv.mlsto + Discipline + client.count + Business +
                              Biz.size + Biz.type + Year + Num.days +
                              no.users + pc.contracttech + client.neginv + client.numinv + client.totinv +
                              pc.director + pc.midtech + pc.midpro + pc.gradpro + pc.seniortech + pc.seniorpro +
                              pc.pro + mean.peeps + hours.perday + num.inv + mean.inv + num.neginv + client.meaninv +
                              code.director + ProjEng.Pos", add.var, sep="+")
        if (type== 'aov') {
            model= aov(as.formula(formula)              
                      ,data= data)
            return(summary(model)) 
        }
        else{
                model=lm(as.formula(formula)                     
                        ,data= data)
                df<- as.data.frame(summary(model)$coefficients)
                df$var<-rownames(summary(model)$coefficients)
                colnames(df)[names(df) %in% 'Pr(>|t|)']<-'Pval'
                return(df %>% arrange(-abs(Estimate)))
                
        }
            
                
}
```

```{r}

# BT.lin(type= 'lm', data= all7a[1:1313,], add.var = 'Job.Type.Primary') %>% slice(1:20)
BT.lin(type= 'lm', data= all7a, add.var = 'Job.Type.Primary') %>% slice(1:20)
BT.lin(type= 'lm', data= all7a[1314:2283,], add.var = 'Job.Type.Primary') %>% slice(1:10)
BT.lin(type= 'aov', data= all7a, add.var = 'Job.Type.Primary')
BT.lin(type= 'aov', data= all7a[1314:2283,], add.var = 'Job.Type.Primary')

```

Most influential variables are:

* Business type
* director code
* Discipline
* Biz.type


Excluded variables include:

* Post.Code
* Billing.Type
* Job.Source
* Job.Detail.Primary
* Job.Detail.Secondary
* Job.Type.Primary
* Job.Type.Secondary
* State
* Type
* no.employees
* contact.count
* JD.Primary
* JD.Second
* dist
* timespan (won't know to begin with)
* Num.disc
* Inv.freq
* client.invfreq

# Correlation Analysis - Numeric variables with 'return.pdol' variable

First run Corrgram  - corrgram function
Run as type 'spearman' - non linear

```{r, echo=FALSE}

#### CORRELATION ANALYSIS

# str(all7a)
num.all<- all7a %>% select(client.count, no.employees, dist, charge.ph, no.users, pc.contracttech,
                           pc.director, pc.gradpro, pc.midpro, pc.midtech, pc.seniorpro, pc.seniortech, 
                           pc.unknown, pc.pro, pc.tech, Year, balance.mlsto,
                           timespan, Num.disc, Num.days, mean.peeps, hours.perday, hrs.mlsto, cost.mlsto, 
                           dis.sc.mlsto, 
                           inv.mlsto, return.pdol,
                           num.inv, mean.inv, Inv.freq, num.neginv, client.meaninv, client.invfreq, 
                           client.neginv, 
                           client.numinv,
                           client.totinv)
corrgram(num.all %>% select(client.count, charge.ph, no.users, pc.director, pc.gradpro, pc.midpro, 
                            pc.midtech, pc.contracttech, return.pdol,
                            pc.seniorpro, pc.seniortech, balance.mlsto,
                            pc.unknown, pc.pro, pc.tech, Year, Num.days, mean.peeps, hours.perday, hrs.mlsto, 
                            cost.mlsto,
                            dis.sc.mlsto, inv.mlsto, num.inv, mean.inv, client.meaninv, client.totinv,
                            timespan) %>% filter(complete.cases(.)), order=T, 
         lower.panel = panel.shade,
         upper.panel = panel.pie,
         text.panel = panel.txt,
         cor.method = 'spearman')
# summary(num.all)
# num.all[rowSums(is.na(num.all))>0,]
```

Now output cor.test results for all numeric variables using both pearson (linear) and kendall (non-linear) to compare.
Kendall does not have problems with ties

```{r, echo=FALSE}

#correlation by each variable against return.perdol individually - numeric variables only

cor.all<- c("client.count", "no.users", "pc.director", "pc.gradpro", "pc.midpro", 
            "pc.midtech", "pc.contracttech", "return.pdol","Inv.freq", 'num.neginv','client.invfreq','client.neginv',
            "pc.seniorpro", "pc.seniortech", "no.employees", "dist", "Num.disc",'client.numinv',
            "pc.unknown", "pc.pro", "pc.tech", "Year", "Num.days", "mean.peeps", "hours.perday", "hrs.mlsto", 
            "cost.mlsto",
            "dis.sc.mlsto", "inv.mlsto", "num.inv", "mean.inv", "client.meaninv", "client.totinv",
            "timespan")

summ<- data.frame("test"=NULL,
                  'var' = NULL,
                  'corr' = NULL,
                  'p.val' = NULL)

for(i in 1:length(cor.all)) {
        
        a = cor.test(all7a$return.pdol, all7a[,cor.all[i]], method = c('pearson'))

        b = cor.test(all7a$return.pdol, all7a[,cor.all[i]], method = c('kendall'))
        
        inter.summ = data.frame('test'= c('pearson','kendall'),
                                'var' = c(cor.all[i], cor.all[i]),
                                'corr' = c(a$estimate, b$estimate),
                                'p.val' = c(a$p.val, b$p.val))
        
        summ = rbind(summ,inter.summ)
}

summ$p.val <- format(summ$p.val, scientific=TRUE, digits = 3)
summ$p.val <- as.numeric(summ$p.val)
summ$corr <- round(summ$corr, 3)

```

Output ordered by p value
```{r, echo=TRUE}

summ %>% arrange(test, p.val)

```

Output ordered by correlation value - only 'significant' results to 5%

```{r}

summ %>% filter(p.val<= 0.05) %>% arrange(test, -abs(corr))

```

From this list it can be concluded what the most influential variables are. 
For the purposes of return.pdol prediction, cost.mlsto, hrs.mlsto, Num.days, dis.sc.mlsto,
num.neginv, Year (won't help in the future) cannot be known. 

This leaves the following important variables:

```{r, echo=FALSE}
kable(
        summ %>% filter(p.val<= 0.05, test== 'kendall') %>% arrange(test, -abs(corr)) %>% 
                select(var, p.val, corr) %>%
                filter(var!= 'cost.mlsto', var!= 'hrs.mlsto', var!= 'Num.days', var!= 'dis.sc.mlsto',
                       var!= 'num.neginv',var!= 'Year', var!= 'return.pdol')
         )

```



# Strength of association with Categorical variables

Use cforest from party package - (Strobl etc, 2007)

* must be subsampling without replacement
* subsampling size 0.632 times recommended because about 63.2% of data end up in bootstrap sample
* cforest defauly is unbiased - for unbiased variable importance as per Strobl etc 2007
* since variables are potentially correlated to one another, need to set conditional permutation importance varimp(obj, conditional=TRUE)
    * This iterates each variable against correlated variables in a controlled way. Ie the target variable is assessed against subgroups of the data where a correlated variable is constant.
    
For cforest, NA values are not handled. Therefore create a 'core' dataframe consisting of the variables which have very low NA entries (say max 10) and delete all NA rows or impute.

State- impute QLD
Business - 22 NA values - impute 'unknown'
Biz.size - 38 NA's - find median, impute?
Biz.type - 18 NA's impute???
charge.ph - delete
charge.pc - delete
Start.Date - delete
End.Date - delete
no.users - 4 NA values - impute
pc.usersss - 7 NA's - what to do. 0 for all? averages for all?
Num.disc - 84 NA's - impute 1?
num.inv and mean.inv- 1 NA?
code.ProjEng - impute: all from pre 2005. All projEng can = director for that job
code.director - impute only 'unknown' to be S121 - by far the majority and fits job description



```{r core_creation, include=FALSE}
#impute NA values in some variables to be in core, call this all7b
all7b<- all7a
all7b[is.na(all7b$State),]$State <- 'QLD'
#RSL Care client - now have details
all7b[all7b$code.client %in% 'C2835',]$no.employees <- 1001
all7b[all7b$code.client %in% 'C2835',]$Biz.type <- 'NFP'
all7b[all7b$code.client %in% 'C2835',]$Business <- 'developer/real estate'
all7b[all7b$code.client %in% 'C2758',]$Biz.size <- 'national'
all7b[all7b$code.client %in% 'C2758',]$no.employees <- 2
all7b[all7b$code.client %in% 'C2758',]$Biz.size <- 'local'
all7b[all7b$code.client %in% 'C2758',]$Business <- 'business'
all7b[all7b$code.client %in% 'C2326',]$Business <- 'health'
all7b[all7b$code.client %in% 'C2338',]$Biz.size <- 'local'
all7b[all7b$code.client %in% 'C2338',]$Business <- 'developer/real estate'
all7b[all7b$code.client %in% 'C2338',]$Biz.type <- 'private'
all7b[all7b$code.client %in% 'C2882',]$Biz.size <- 'local'
all7b[all7b$code.client %in% 'C2882',]$Business <- 'builder'
all7b[all7b$code.client %in% 'C2882',]$Biz.type <- 'private'
all7b[all7b$code.client %in% 'C2882',]$no.employees <- 3
#all remaining NA Business will be 'unknown'
all7b$Business<- as.character(all7b$Business)
all7b[is.na(all7b$Business),]$Business <- 'unknown'
all7b$Business<- as.factor(all7b$Business)

#impute Biz.size to be 'local' by default - this is most popular category
all7b[is.na(all7b$Biz.size),]$Biz.size <- 'local'
#impute Biz.type to be 'private' by default - this is most popular category
#client which is 'department of national parks' shall be 'gov'
all7b[is.na(all7b$Biz.type),]$Biz.type <- 'private'
all7b[all7b$code.client %in% 'C2503',]$Biz.type <- 'gov'
#delete charge.ph and charge.pc, Start.Date and End.Date
all7b<- all7b %>% select(-charge.ph, -charge.pc, -End.Date)
#impute NA no.users as 2 = median and mode
all7b[is.na(all7b$no.users),]$no.users <- 2
#impute NA num.disc as 1 - overwhelmingly the most common
all7b[is.na(all7b$Num.disc),]$Num.disc <- 1
#num.inv and mean.inv both have a single NA value
# this consisted of single large -ve invoice. I think we should delete this case 
all7b<- all7b %>% filter(!is.na(num.inv))
# 7 NA cases with significant dis.sc.mlsto - ie done by contractor 
pc<- c('pc.contracttech','pc.director', 'pc.midtech', 'pc.midpro', 'pc.gradpro', 'pc.seniortech', 'pc.seniorpro', 'pc.pro', 'pc.tech')

for (i in 1:length(pc)){
        all7b[is.na(all7b[,pc[i]]),][,pc[i]] <-0
}

#impute code.director Unknown to be S168
all7b[all7b$code.director == 'Unknown',]$code.director<-'S168'
all7b$code.director<- droplevels(all7b$code.director)
#impute code.ProjEng to be Director codes for that job
all7b[is.na(all7b$code.ProjEng),]$code.ProjEng<- all7b[is.na(all7b$code.ProjEng),]$code.director
all7b$code.ProjEng<- droplevels(all7b$code.ProjEng)

#redo client.count and contact.count according to this reduced dataset!!
client.count<- ddply(all7b, .(code.client), nrow)
all7b<- merge(all7b, client.count, by='code.client', all.x=TRUE)
all7b %>% select(code.client, client.count, V1) %>% slice(1000:1020)
all7b<- transform(all7b, diff= client.count - V1)
# all7b %>% select(code.client, client.count, V1, diff) %>% unique %>% arrange(-diff) %>% head
#above line tells us that our most popular clients are also the ones with the most lost jobs - fine
all7b$client.count<- all7b$V1
all7b<- all7b %>% select(-diff, -V1)


#change unknown Num.disc to be 1
all7b[is.na(all7b$Num.disc),]$Num.disc <- 1

#create new variable - tech.pos
all7b %>% select(pc.contracttech, pc.midtech, pc.seniortech) %>% slice(1000:1020)
test<- melt(all7b %>% select(mlsto, pc.contracttech, pc.midtech, pc.seniortech))
test<- ddply(test, .(mlsto), max= max(value))
#delete any rows where percentage is less than 10
test<- test[!test$value<10,] %>% arrange(mlsto,-value)
#now I just want the first row for every milestone - ie tech person that did the MOST
test2<- ddply(test, .(mlsto), function(x) head(x,1))
#now delete pc from the front of all the variables
test2$variable<- sapply(test2$variable,FUN=function(x){
        substr(x,4,15)})
test2$variable<- as.factor(test2$variable)
test2$value.bin<- cut(test2$value,9)
table(test2$variable, test2$value.bin)
mosaicplot(test2$variable ~ test2$value.bin, color=brewer.pal(9,"Spectral"),
           cex.axis = .5)
all7b<- merge(all7b, test2 %>% select(mlsto, variable), by='mlsto', all.x=TRUE, all.y=FALSE)
colnames(all7b)[names(all7b) %in% 'variable']<-'pos.tech'

#create new variable - majority.pos
all7b %>% select(pc.contracttech, pc.midtech, pc.seniortech, pc.director, pc.seniorpro, pc.midpro) %>% slice(1000:1020)
testa<- melt(all7b %>% select(mlsto, pc.contracttech, pc.midtech, pc.seniortech, pc.director, pc.gradpro,
                             pc.midpro, pc.seniorpro, pc.unknown))
#delete any rows where percentage is less than 10
testa<- testa[!testa$value<10,] %>% arrange(mlsto,-value)
#now I just want the first row for every milestone - ie tech person that did the MOST
testa2<- ddply(testa, .(mlsto), function(x) head(x,1))
#now delete pc from the front of all the variables
testa2$variable<- sapply(testa2$variable,FUN=function(x){
        substr(x,4,15)})
testa2$variable<- as.factor(testa2$variable)
#create bins for mosaic plot
testa2$value.bin<- cut(testa2$value,5)
table(testa2$variable, testa2$value.bin)
#reorder levels for mosaic plot
testa2$variable <- factor(testa2$variable, levels=names(sort(table(testa2$variable), 
                                                                 decreasing=TRUE)))
mosaicplot(testa2$variable ~ testa2$value.bin, color=brewer.pal(9,"Spectral"),
           cex.axis = .6)
all7b<- merge(all7b, testa2 %>% select(mlsto, variable), by='mlsto', all.x=TRUE, all.y=FALSE)
colnames(all7b)[names(all7b) %in% 'variable']<-'majority.pos'
all7b[all7b$majority.pos %in% 'unknown',]$majority.pos<- NA

#create new variable - pc.majpos - percentage done by majority position
all7b<- merge(all7b, testa2 %>% select(mlsto, value), by='mlsto', all.x=T, all.y=F)
#if majority.pos is unknown, then value must be unknown - NA
all7b$value<- ifelse(is.na(all7b$majority.pos), NA, all7b$value)
colnames(all7b)[names(all7b) %in% 'value']<-'pc.majpos'

write.csv(all7b,'all7b.csv')
all7b<- read.csv('all7b.csv')[,-1]
 
```



# New Variable - client age

```{r, echo=FALSE}
#read csv file with all the client details - want to merge this with client df
# details<- read.csv('17marchclients.csv',
#                    na.strings = c("", " ", "NA"))
# head(details)
# #delete client.contact, client.count, and contact.count columns
# details<- details[,c(1,5:9)]
# #rename columns
# names(details)[2]<- 'Business'
# names(details)[4]<- 'Biz.size'
# names(details)[5]<- 'Biz.type'
# names(details)[6]<- 'Biz.age'
# 
# #delete rows with 4 NA values
# details<-details[rowSums(is.na(details))!=5,]
# details<-details[rowSums(is.na(details))!=4,]
# 
# #add row for client code
# code.client<- read.csv('code_client2.csv')[,-1]
# details<- merge(details, code.client, by.x ='client', by.y ='client2', all.x=TRUE, all.y=FALSE)
# details<- transform(details, client.age = 2014- Biz.age)
# 
# #merge client.age column of details to all7b by code.client
# all7b<- merge(all7b, details %>% select(code, client.age), by.x = 'code.client', by.y = 'code', all.x=TRUE, all.y=FALSE)


write.csv(all7b, 'all7c.csv')
all7c<- read.csv('all7c.csv')[,-1]

```

See how variable selection goes with random forest first, then probably just run cforest again without code.client and contact.code

Use cforest to test remaining variables (with significant NA components)

These include:

* code.client
* Post.Code
* Billing.Type
* Job.Source
* Job.Detail.Primary
* Job.Detail.Secondary
* Job.Type.Primary
* Job.Type.Secondary
* Type
* Project.Value
* no.employees
* client.age
* contact.count
* JD.Primary
* JD.Second
* dist
* code.contact
* client.age

First eliminate some of the job.detail.secondary - that kind of thing
Then see if any have matching NA rows
Then run cforest on each variable individually


```{r eliminate sme variables, echo=FALSe}
#between Job.Detail.Primary, Job.Detail.Secondary, Job.Type.Primary, Job.Type.Secondary, Type, JD.Primary, JD.Second
# need to delete some

#Job.Detail.Primary - 1A, 1B, 1C and so on. 1215 NA values - delete
#JD.Primary - 1A, 1B, 1C and so on. 628 NA values
#Job.Detail.Secondary - 1A, 1B, 1C and so on. 2090 NA values - most don't make sense (ARch housing with industrial buidling) 
#                                                            - industrial bldg with land subdivision - checked out, all wrong!
#        - some do ie 2C Sustainable design with 2B water-sensitive urban design (WSUD) - use!
#        - some do  ie 3C integrated water management and WSUD and 4C alternative sources of water supply - use!

#Job.Type.Primary - eg 1. Building Structures, 628 NA values, quite useful - guessing that it matches JD.Primary NA values


#Job.Type.Secondary - confusing
#                   - 2. LandInfrastucture could be copied into land subdivision for Job.Detail.Secondary
all7c$Job.Detail.Secondary <- as.character(all7c$Job.Detail.Secondary)
all7c$Job.Detail.Secondary<- ifelse(all7c$Job.Detail.Secondary=='2E Land Subdivision' & all7c$Job.Type.Secondary=='2. LandInfrastructure',
                                    '2. LandInfrastructure', all7c$Job.Detail.Secondary)
all7c$Job.Detail.Secondary<- ifelse(is.na(all7c$Job.Detail.Secondary) & all7c$Job.Type.Secondary=='2. LandInfrastructure',
                                    '2. LandInfrastructure', all7c$Job.Detail.Secondary)
all7c$Job.Detail.Secondary <- as.factor(all7c$Job.Detail.Secondary)

#                   - copy '4. Integrated water management' as 'water management' into JD.Second
all7c$JD.Second <- as.character(all7c$JD.Second)
all7c$JD.Second<- ifelse(is.na(all7c$JD.Second) & all7c$Job.Type.Secondary=='4. IntegratedWaterManagement',
                                    'water management', all7c$JD.Second)
all7c$JD.Second <- as.factor(all7c$JD.Second)


# Type - short description - quite good - 1206 NA's - all 2010 or earlier

#JD.Second - more detailed version of JD.Primary- 1277 NA's - across all years - keep

all7c<- all7c %>% select(-Job.Detail.Primary, -Job.Type.Secondary)

# write.csv(all7c, 'all7c.csv')
# all7c<- read.csv('all7c.csv')[,-1]

```

First need to change code.client and code.contact. Need to assign NA to any code.client or code.contact with less than 2 counts

```{r NA into code.client, echo=FALSE}
#Job.Source - 'twitter' should be NA
all7c[all7c$Job.Source %in% 'Twitter',]$Job.Source<- NA

#Billing.Type - 'Estimate' and 'FeeProposal' and 'NoCharge' should be NA
all7c[all7c$Billing.Type %in% c('Estimate','FeeProposal','No Charge'),]$Billing.Type<- NA

#code.ProjEng - 'Unknown' should be NA
all7c[all7c$code.ProjEng %in% c('Unknown'),]$code.ProjEng<- NA

#ProjEng.Pos - 'Unknown' should be NA
all7c[all7c$ProjEng.Pos %in% c('Unknown'),]$ProjEng.Pos<- NA

#code.Eng2 - 'Unknown' should be NA
all7c[all7c$code.Eng2 %in% c('Unknown'),]$code.Eng2<- NA


#all code.clients with counts less than 3 shall be 'NA'
client.check<- ddply(all7c,.(code.client), nrow)
all7c<- merge(all7c, client.check, by='code.client', all.x=TRUE)
all7c$code.client<- as.character(all7c$code.client)
all7c$code.client<- ifelse(all7c$V1>1, all7c$code.client, NA)
all7c$code.client<- as.factor(all7c$code.client)
all7c<- all7c %>% select(-V1)

#all code.contacts with counts less than 3 shall be 'NA'
#code for 'unknown' which should be NA
all7c[all7c$code.contact %in% 'CN1983',]$code.contact <- NA
contact.check<- ddply(all7c,.(code.contact), nrow)
contact.check<- contact.check %>% filter(V1>1)
all7c$code.contact<- as.character(all7c$code.contact)
all7c$code.contact<- ifelse(all7c$code.contact %in% contact.check$code.contact, all7c$code.contact,
                            NA)
all7c$code.contact<- as.factor(all7c$code.contact)

#redo contact.count
cont.count<- ddply(all7c,.(code.contact), nrow)
cont.count[is.na(cont.count$code.contact),]$V1<- NA
all7c<- merge(all7c, cont.count, by='code.contact', all.x=TRUE)
all7c$contact.count<- all7c$V1
all7c<- all7c %>% select(-V1)

#Project.Value - anything with '0' should be 'NA'
all7c[all7c$Project.Value == 0,]$Project.Value<- NA
#check out what the ratios of inv.mlsto/Project.Value are
temp<- all7c %>% select(Project.Value, inv.mlsto,mlsto) %>% filter(!is.na(Project.Value))
temp<- transform(temp, ratio = round(inv.mlsto/Project.Value*100,2))
temp<- temp %>% filter(ratio< 16)
all7c$Project.Value<- ifelse(all7c$mlsto %in% temp$mlsto, all7c$Project.Value, NA)

#delete outliers : return.pdol>30 GONE
all7c %>% filter(return.pdol>3) %>% select(return.pdol, inv.mlsto, hrs.mlsto, dis.sc.mlsto,mlsto, cost.mlsto) %>% arrange(-return.pdol)
all7c<- all7c %>% filter(!return.pdol>3)

#drop levels in each variable
all.vars<- colnames(all7c)
for (i in 1:length(all.vars)){
        if(all7c[,all.vars[i]] %>% class == 'factor'){
        all7c[,all.vars[i]]<- droplevels(all7c[,all.vars[i]])
        }
        
}

write.csv(all7c, 'all7c.csv')

all7c<- read.csv('all7c.csv')[,-1]
all7c$Post.Code<- as.factor(all7c$Post.Code)

```



Start running cforests on core list of variables

```{r, echo=FALSE}

#create core data frame - variables with very few NA's and delete these NA's

core<- all7c %>% select(code.client , Discipline ,  client.count , inv.mlsto , Business ,
        Biz.size , Biz.type , no.users , Year , timespan , Num.disc , Num.days , mean.peeps,
        pc.contracttech , hours.perday , profit.mlsto , balance.mlsto , hrs.mlsto , 
        cost.mlsto , dis.sc.mlsto , inv.mlsto , return.pdol , code.contact ,
        pc.director , pc.midtech , pc.midpro , pc.gradpro , pc.seniortech , pc.seniorpro ,
        pc.pro , code.director , code.ProjEng , ProjEng.Pos , num.inv , mean.inv , num.neginv , 
        client.meaninv , client.neginv , client.numinv , client.totinv)

mini.core2 <- all7c %>% select(code.client , Discipline ,  client.count , inv.mlsto , Business ,
        Biz.size , Biz.type , no.users , timespan, Num.disc, 
        return.pdol, code.contact,
        pc.director,
        pc.pro , code.director , ProjEng.Pos , code.ProjEng,
        client.meaninv , client.neginv , client.numinv , client.totinv)

mini.core3 <- all7c %>%
        select(Discipline , inv.mlsto , Business, client.count,
        Biz.size , Biz.type , no.users , timespan, Num.disc, 
        return.pdol,
        pc.pro , code.director , 
        client.meaninv , client.neginv , client.numinv , client.totinv)

```


Try running a cforest over night with full dataset - don't include 


```{r, echo=FALSE}

system.time(
all.cfor2<- cforest(return.pdol~.,
        data= mini.core3
        )
)

var.imp<- varimp(all.cfor2) %>% as.data.frame
colnames(var.imp)[names(var.imp) %in% '.']<-'imp'
var.imp$var <- rownames(var.imp)
#reorder levels for bar plot
var.imp <- within(var.imp, 
                    var <- factor(var,levels=
                                            var.imp[order(-abs(var.imp$imp)),]$var))

q<- ggplot(data=var.imp, aes(x=var, y=imp)) + theme(axis.text.x=element_text(angle=45,hjust=1))
q + geom_bar(stat='identity')

save(all.cfor2,file= 'C:/Users/n9232371/Documents/Consultbusiness/data/objects/all_cfor2.RData')
# load('C:/Users/n9232371/Documents/github/consult/object/all_cfor2.RData')


```

From analysing all jobs including 2009 and beyond, the most important variables are:
`levels(var.imp$var) %>% as.data.frame %>% slice(1:8)`

The least important are 
`levels(var.imp4$var) %>% as.data.frame %>% slice(9:16)`

Let's compare this to 

* all data from 2002 to 2014 - currently running in another R window
* ANOVA - all data because fast
* random forest

## Anova:

```{r anova_varimp, echo=FALSE}
#use mini.core2- all years

aov.all<- aov(return.pdol~.,
              data= mini.core3)

summary(aov.all)
```

Therefore most significant variables are:

* no.users - number of people on the job - << 1%
* timespan - << 1%
* Discipline - <<1%
* inv.mlsto - 8.9%
* Business << 1%
* Biz.type - 2%
* pc.pro - .13%

worst: Biz.size, client.numinv, client.neginv, client.meaninv, client.totinv, pc.director, Num.disc, Biz.size

Contrasts to cforest results include

* Num.disc
* pc.director
* Biz.size
* Biz.type = cforest rated this very low



# random forests

First optimise parameters mtry and ntree - exclude code.client and code.contact for now as they have way too many categories

```{r randomForest, echo=FALSE}
#random forest can have max 53 categories in a variable
#code.client has the most categories - 664

# find optimal mtry

#create train/test sets

train_ind <- sample(seq_len(nrow(mini.core3)), size = 1546)

train <- mini.core3[train_ind, ]
test <- mini.core3[-train_ind, ]
oob.err<-double(13)
test.err<-double(13)
for(mtry in 1:13){
        fit<-randomForest(return.pdol ~., data=train, mtry=mtry, ntree=400)
        oob.err[mtry]<-fit$mse[400]
        test.err[mtry]<- mean((predict(fit,test)-test$return.pdol)^2)
        cat(mtry," ")
}

qplot(1:mtry,test.err,geom=c("point","line"),color="pink")+
        geom_line(aes(1:mtry,oob.err,colour="blue"))+
        geom_point(aes(1:mtry,oob.err, colour="blue"))

#USE MTRY = 5, NOW VARY NUMBER OF TREES

trees<- c(300,500,700,1000,1500)
oob.err<-double(5)
test.err<-double(5)
for(ntree in 1:5){
        fit<-randomForest(return.pdol ~., data=train, mtry=5, ntree=trees[ntree])
        oob.err[ntree]<-fit$mse[trees[ntree]]
        test.err[ntree]<- mean((predict(fit,test)-test$return.pdol)^2)
        cat(ntree," ")
}

qplot(1:ntree,test.err,geom=c("point","line"),color="pink")+
        geom_line(aes(1:ntree,oob.err,colour="blue"))+
        geom_point(aes(1:ntree,oob.err, colour="blue"))

#use 500 trees
```

Extract important variables from randomForest loop

423 of the 664 client companies and 485 of the 670 client contacts appear ONLY once in the entire data set.
While they may be great predictors what do we do in the majority of cases where the contact is new!?

```{r, echo=FALSE}
set.seed(47)

#try running without code.client or code.contact
multi.forest1<-function(data=mini.core3, nforest=1:10){
        sample=double(50)
        imp = NULL
        for (i in 1:length(nforest)){
                
                #run tree
                assign(paste("Forest",i,sep=""),randomForest(return.pdol~.,
                                                             data=data,
                                                             ntree=400,mtry=5, importance=TRUE),
                       envir=.GlobalEnv)
                
                #put together importance rank for each variable
                
                rand.imp= importance(paste("Forest",i,sep="") %>% get, type=1, scale=FALSE) %>% as.data.frame
                colnames(rand.imp)[names(rand.imp) %in% '%IncMSE']= 'IncMSE'
                rand.imp$var= rownames(rand.imp)
                rand.imp= rand.imp %>% arrange(-abs(IncMSE))
                rand.imp$rank= 1:nrow(rand.imp)
                
                #rbind all variables and ranks on top of one another for each Forest
                
                imp = rbind(imp, rand.imp %>% select(var,rank))

                cat(i," ")
                
        }
        
        #output average rank of each variable
        rank = ddply(imp, .(var), summarise, m.rank =mean(rank)) %>% arrange(m.rank)
        return(rank)
        
}

rand.rank<- multi.forest1(data=mini.core3, nforest=1:10)

kable(rand.rank)

```

* no.users - number of people on the job - << 1%
* timespan - << 1%
* Discipline - <<1%
* inv.mlsto - 8.9%
* Business << 1%
* Biz.type - 2%
* pc.pro - .13%

Keep:

* inv.mlsto
* timespan
* no.users
* Discipline
* pc.pro
* client.totinv
* pc.director
* code.director
* Num.disc
* Business
* Biz.type
* Biz.size

Dump

* client.neginv
* client.count
* ProjEng.Pos
* client.numinv
* client.meaninv


#### YOU ARE HEREE #####




now left with 

* ProjEng.Pos
* code.ProjEng
* code.client
* Post.Code
* Billing.Type
* Job.Source
* Job.Detail.Secondary
* Job.Type.Primary
* Type
* Project.Value
* no.employees
* client.age
* contact.count
* JD.Primary
* JD.Second
* dist
* code.contact
* client.age
* majority.pos

Do any of these have significantly overlapping NA values???

```{r NA overlap, echo=FALSE}

#overlapping NA values for variables with many NA's
# first lets look at Job.Detail.Secondary, Job.Type.Primary, Type, JD.Primary, JD.Second
experiment<- all7c
experiment<- experiment %>% select(code.client, Post.Code, Billing.Type, Job.Source, Job.Detail.Secondary, 
                                   Job.Type.Primary, Type, Project.Value,
                                   no.employees, client.age, contact.count, JD.Primary, JD.Second, dist, code.contact,
                                   client.age, ProjEng.Pos, code.ProjEng, majority.pos, pc.majpos )
experiment<- sapply(experiment, function(x) is.na(x))
NA.plot<- melt(experiment)
NA.plot$mlsto<- rep(all7c$mlsto, ncol(experiment))
#reorder levels for ggplot by total number of NA TRUE
# table(NA.plot$Var2, NA.plot$value)[,'TRUE']
NA.plot <- within(NA.plot, 
                         Var2 <- factor(Var2, 
                                               levels=names(sort(table(NA.plot$Var2, NA.plot$value)[,'TRUE'], 
                                                                 decreasing=FALSE))))

ggplot(NA.plot, aes(x=Var2, y=mlsto)) +
        geom_tile(aes(fill = value)) + 
        theme(axis.text.x=element_text(angle=45,hjust=1))

```

Yes, 

* dist and Post.Code
* Job.Type.Primary and JD.Primary
* code.contact and contact.count
* ProjEng.Pos and code.ProjEng

For now, we will treat the rest as having 'different 

Run 12 cforests with the core variables!!

```{r cforests for NAs, echo=FALSE}


#function to create a subset dataframe based on extra variable
#then runs cforest, and saves variable importance ggplot in a folder

vars<- list('Job.Source', 'Job.Detail.Secondary', 'Type', 'Project.Value', 'no.employees',
            'code.client',
            'client.age', 'contact.count', 'JD.Second', 'Billing.Type', 'pos.tech', 
            'majority.pos', 'pc.majpos',
            c('dist','Post.Code'),
            c('code.contact','contact.count'), c('Job.Type.Primary','JD.Primary'),
            c('ProjEng.Pos', 'code.ProjEng'))

cfor.plotsave<- function(extra= vars, name= 'vare'){
        for(i in 1:length(vars)){
                
                core.var= all7c[,names(all7c) %in% c('inv.mlsto', 'timespan', 'no.users', 
                                                     'Discipline', 'pc.pro', 
                        'client.totinv', 'pc.director', 'code.director', 'Num.disc', 
                        'Business', 'Biz.type', 'Biz.size', 'return.pdol', extra[[i]])]
                core.var = core.var[!is.na(core.var[,extra[[i]][1]]),]
        
                #run cforest
                cfor.var1= cforest(return.pdol~.,
                                   data= core.var)
                #calculate variable importances
                var.imp= varimp(cfor.var1) %>% as.data.frame
                colnames(var.imp)[names(var.imp) %in% '.']= 'imp'
                var.imp$var = rownames(var.imp)
                #reorder levels for bar plot
                var.imp<- within(var.imp, 
                    var <- factor(var,levels=var.imp[order(-abs(var.imp$imp)),]$var))
        
                q= ggplot(data=var.imp, aes(x=var, y=imp)) + theme(axis.text.x=element_text(angle=45,hjust=1))
                r=q + geom_bar(stat='identity') + 
                        labs(title = extra[[i]])
                #save plot
                ggsave(plot=r,
                       filename=paste(name,i,'.png',sep=''),
                       path= 'C:/Users/n9232371/Documents/Consultbusiness/barplots/cforests/')
                
                cat(i," ")
                
        }
        
}

cfor.plotsave(extra=vars, name='vara')
cfor.plotsave(extra=vars, name='varb')
cfor.plotsave(extra=vars, name='varc')
cfor.plotsave(extra=vars, name='vard')
cfor.plotsave(extra=list('majority.pos'), name='vare')
        
                   
all7c %>% select(Job.Detail.Secondary) %>% summary

```

From the cforests, the extra variables worth keeping are

* code.contact - ranks 4th after no.users, timespan, pc.pro
* code.client (ranks 4th/4th)
* Project.Value (ranks 4th/5th)
* JD.Second - ranks 6/6th - before code.director and Num.disc / 5th
* Billing.Type - ranks 3rd last/4th last but I can't see how this is not important/last
* Post.Code - 4th
* code.ProjEng - 8th
* majority.pos
* pc.majpos

Throwing out:
* Job.Source - ranked 4th last/3rd last
* Job.Detail.Secondary - too patchy I believe / 5th last/3rd last
* Type - nice and broad but didn't seem to work - ranked 5th last / 3rd last
* client.age - last/last
* contact.count - 4th last/last
* dist - 3rd last/2nd last
* Post.Code - 6th last or 7th last 
* contact.count - last/2nd lsat 
* ProjEng.Pos - 3rd last/ 4th last
* no.employees - 3rd last / 2nd last
* Job.Type.Primary - 3rd last
* JD.Primary - 8th/9th,ie 7th last not too bad - too similar to JD.Second and JD.Second performs better

```{r run anova on all, echo=FALSE}
vars.vec<- c('Job.Source', 'Job.Detail.Secondary', 'Type', 'Project.Value', 'no.employees','code.client',
            'client.age', 'contact.count', 'JD.Second', 'Billing.Type', 'dist','Post.Code',
            'code.contact','contact.count', 'Job.Type.Primary','JD.Primary','ProjEng.Pos', 'code.ProjEng', 'pos.tech',
            'majority.pos', 'pc.majpos')

aov.loop<- function(extra=vars.vec){
        for (i in 1:length(extra)){
                core.var= all7c[,names(all7c) %in% c('inv.mlsto', 'timespan', 'no.users', 
                                                     'Discipline', 'pc.pro', 
                        'client.totinv', 'Biz.type','code.director', 'Num.disc', 
                        'Business', 'return.pdol', extra[i])]
                core.var = core.var[!is.na(core.var[,extra[i]]),]
                
                formula = paste("return.pdol ~ inv.mlsto + Discipline + Business+
                        Biz.type + Num.disc +
                        no.users + 
                        client.totinv + 
                        pc.pro + timespan +
                        code.director", extra[i], sep="+")
                
                model= aov(as.formula(formula)              
                           ,data= core.var)
                
                print(extra[i])
                print(model %>% summary)
                
                cat(i," ")
                }
        }

aov.loop(extra=vars.vec)

#try adding pc.director and pc.seniorpro to make pc.seniorpro.d - didn't go that well

# all7c<- transform(all7c, pc.seniorpro.d = pc.seniorpro+pc.director)


```

From Anova, the only new variables that are significant are:

* Project.Value - 17%
* Post.Code - 23%
* code.contact - 14.4%
* code.client - .25%
* JD.Second - 1.25%
* dist - 17%
* JD.Primary - 9.8% - delete, confusing with JD.Second
* ProjEng.Pos - 1.5%
* code.ProjEng - .9%
* majority.pos - 3.7%

Visualise all categorical variables as boxplots vs return.pdol

```{r boxplots of each variable, echo=FALSE}


auto.BP<- function(yvar = 'return.pdol', df= all7c, name='box'){
        
        colnames= colnames(df %>% select(-mlsto))
        
        #make all boxplot dots match colours
        update_geom_defaults("point", list(colour = NULL))

        for (i in 1:length(colnames)){
                
                #only perform plot if variable is a factor
                #if variable is numeric or an integer, break into 8 bins
                if(df[,colnames[i]] %>% class %in% c('factor')) {
                
                medians= ddply(all7c,.(all7c[,colnames[i]]), summarise, med=median(return.pdol))
                
                df[,colnames[i]] <- factor(df[,colnames[i]], 
                                               levels= medians[order(-medians$med),][,1] )                         
                
                r= ggplot(df[!is.na(df[,colnames[i]]),],
                       aes_string(x=colnames[i], y=yvar, colour = colnames[i])) + 
                        geom_boxplot(alpha = 0, size = .5, outlier.size = .5)+
                        geom_jitter(alpha= 0.5, size=.5) +
                        labs(title = paste(colnames[i], "vs.", yvar, sep=' '),
                        x= colnames[i],
                        y = yvar) + 
                        theme(legend.position = 'none',
                              text = element_text(size =9.5),
                                axis.text.x= element_text(angle=45, hjust=1))+
                        stat_summary(fun.y = mean, geom= 'point', shape = 1, size = .6)
                
                #save plot
                ggsave(plot=r,
                       filename=paste(name,i,'.png',sep=''),
                       path= 'C:/Users/n9232371/Documents/Consultbusiness/barplots/boxplots/')
                
                cat(i," ")  
                }
        
}
}

auto.BP(yvar = 'return.pdol', df= all7c %>% select(mlsto,return.pdol, majority.pos), name='box_maj')


```

Visualise all numerical variables as boxplots vs return.pdol

```{r boxplots numeric vars, echo=FALSE}



autonum.BP<- function(colnames=all.vars, yvar = 'return.pdol', df= all7c, name='box', breaks=4){

        for (i in 1:length(colnames)){
                
                #only perform plot if variable is a factor
                #if variable is numeric or an integer, break into 8 bins
                
                #how many total cols
                        tot.num = df %>% ncol
                        #how many numeric variables?
                        num = df[,!sapply(df, is.factor)] %>% ncol
                        
                if(df[,colnames[i]] %>% class %in% c('numeric', 'integer')) {
#                         print('yes')}
                        
                        #cut numeric columns into new variables with 8 categories, these are called 'cuti' 
                        df[, paste0('cut',i)] <- cut_number(df[,colnames[i]] %>% as.numeric, breaks)
#                         df[, paste0('cut',i)] <- cut_number(df[,colnames[i]] %>% as.numeric, 8)
                        
                
#                 medians= ddply(df,
#                                .(df[,paste0('cut',i)]), summarise, med=median(return.pdol))
                
#                 df[,paste0('cut',i)] <- factor(df[,paste0('cut',i)], 
#                                                levels= medians[order(-medians$med),][,1] )                         
                
                r= ggplot(df[!is.na(df[,paste0('cut',i)]),],
                       aes_string(x=paste0('cut',i), y=yvar, colour = paste0('cut',i))) + 
                        geom_boxplot(alpha = 0, size = .8, outlier.size = 1)+
                        geom_jitter(alpha= 0.4, size=1) +
                        labs(title = paste(colnames[i], "vs.", yvar, sep=' '),
                        x= colnames[i],
                        y = yvar) + 
                        theme(legend.position = 'none',
                              text = element_text(size =12),
                                axis.text.x= element_text(angle=45, hjust=1))+
                        stat_summary(fun.y = mean, geom= 'point', shape = 2, size = 1)
                
                #save plot
                ggsave(plot=r,
                       filename=paste(name,i,'.png',sep=''),
                       path= 'C:/Users/n9232371/Documents/Consultbusiness/barplots/boxplots/')
                
                cat(i," ")  
                }
        
}
}

df<- all7c %>% select(-X, -No.Blue.Files, -contact.count, -no.users, -pc.contracttech,
                      -pc.director, -pc.gradpro, -pc.midpro, -pc.midtech,-pc.seniorpro, -pc.seniortech,
                      -pc.unknown, -pc.pro, -pc.tech, -Year, -Num.disc, -mean.peeps,
                      -dis.sc.mlsto, -num.inv, -num.neginv, -client.neginv, -client.count)
all.vars<- colnames(df)
autonum.BP(colnames=all.vars, yvar = 'return.pdol', df= df, name='boxnum', breaks=8)


```



Visualise all percent variables, cut into 5, ie 0-20%, 20-40% etc

```{r boxplots numeric vars, echo=FALSE}



autopc.BP<- function(colnames=all.vars, yvar = 'return.pdol', df= df1, name='box', breaks=5){

        for (i in 1:length(colnames)){
                
                #how many total cols
                        tot.num = df %>% ncol
                        #how many numeric variables?
                        num = df[,!sapply(df, is.factor)] %>% ncol
                        
                if(df[,colnames[i]] %>% class %in% c('numeric', 'integer')) {
#                         print('yes')}
                        
                        #remove rows which =0
                        df2<- df[!(df[,colnames[i]] == 0),]
                        #cut numeric columns into new variables with 8 categories, these are called 'cuti' 
                        df2[, paste0('cut',i)] <- cut(df2[,colnames[i]] %>% as.numeric, breaks)
#                         df[, paste0('cut',i)] <- cut_number(df[,colnames[i]] %>% as.numeric, 8)
                        
                
#                 medians= ddply(df,
#                                .(df[,paste0('cut',i)]), summarise, med=median(return.pdol))
                
#                 df[,paste0('cut',i)] <- factor(df[,paste0('cut',i)], 
#                                                levels= medians[order(-medians$med),][,1] )                         
                
                r= ggplot(df2[!is.na(df2[,paste0('cut',i)]),],
                       aes_string(x=paste0('cut',i), y=yvar, colour = paste0('cut',i))) + 
                        geom_boxplot(alpha = 0, size = .8, outlier.size = 1)+
                        geom_jitter(alpha= 0.4, size=1) +
                        labs(title = paste(colnames[i], "vs.", yvar, sep=' '),
                        x= colnames[i],
                        y = yvar) + 
                        theme(legend.position = 'none',
                              text = element_text(size =12),
                                axis.text.x= element_text(angle=45, hjust=1))+
                        stat_summary(fun.y = mean, geom= 'point', shape = 2, size = 1)
                
                #save plot
                ggsave(plot=r,
                       filename=paste(name,i,'.png',sep=''),
                       path= 'C:/Users/n9232371/Documents/Consultbusiness/barplots/boxplots/')
                
                cat(i," ")  
                }
        
}
}

df1<- all7c %>% select(pc.contracttech, return.pdol,
                      pc.director, pc.gradpro, pc.midpro, pc.midtech,pc.seniorpro, pc.seniortech,
                      pc.unknown, pc.pro, pc.tech, Year, mean.peeps, dis.sc.mlsto)
all.vars<- colnames(df1)
autopc.BP(colnames=all.vars, yvar = 'return.pdol', df= df1, name='boxpc', breaks=5)

#test - added pc.seniorpro and pc.director together - didn't go that well
# trial<- c('pc.seniorpro.d')
# autopc.BP(colnames=trial, yvar = 'return.pdol', df= all7c %>% select(return.pdol,pc.seniorpro.d), name='boxpca', 
#           breaks=5)





```

Plot integers which don't need cutting

```{r, echo=FALSE}

autoint.BP<- function(colnames=all.vars, yvar = 'return.pdol', df= all7c, name='boxint'){

        for (i in 2:length(colnames)){                        
                
                df[,colnames[i]]<- as.factor(df[,colnames[i]])
                
                r= ggplot(df[!is.na(df[,colnames[i]]),],
                       aes_string(x=colnames[i], y= yvar, colour = colnames[i] )) + 
                        geom_boxplot(alpha = 0, size = .8, outlier.size = 1)+
                        geom_jitter(alpha= 0.4, size=1) +
                        labs(title = paste(colnames[i], "vs.", yvar, sep=' '),
                        x= colnames[i],
                        y = yvar) + 
                        theme(legend.position = 'none',
                              text = element_text(size =12),
                                axis.text.x= element_text(angle=45, hjust=1))+
                        stat_summary(fun.y = mean, geom= 'point', shape = 2, size = 1)
                
                #save plot
                ggsave(plot=r,
                       filename=paste(name,i,'.png',sep=''),
                       path= 'C:/Users/n9232371/Documents/Consultbusiness/barplots/boxplots/')
                
                cat(i," ")  
                }
        
}

df<- all7c %>% select(return.pdol, No.Blue.Files, contact.count, no.users, Num.disc,
                      num.inv, num.neginv, client.neginv, client.count)
all.vars<- colnames(df)
autoint.BP(colnames=all.vars, yvar = 'return.pdol', df= df, name='boxint')

```




