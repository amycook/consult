---
title: "R Notebook"
output:
  word_document: default
  html_notebook: default
---

```{r, echo=FALSE, include=FALSE}

library('knitr')
library('ggplot2')
library("plyr")
library("dplyr")
library('magrittr')
library('reshape2')
library("rpart")
library('car')
library('e1071')
library('party')
library('randomForest')
library('RColorBrewer')
library('pwr')
library('scales')


# detect OS
if(.Platform$OS.type == 'windows'){
        # setwd("C:/Users/n9232371/Documents/Consultbusiness/data")
        opts_knit$set(root.dir= "C:/Users/n9232371/Documents/github/consult/finalwriteup/report_data")
} else{
        # setwd("~/OneDrive/shared files/Bligh Tanner/masters/data")
        # setwd("~/Documents/github/consult/finalwriteup/report_data")
        opts_knit$set(root.dir= '~/Documents/github/consult/finalwriteup/report_data')
}

opts_chunk$set(fig.width=6.7, dpi = 300, warning = FALSE, message = FALSE, echo = FALSE)
```


$odds = e^{\ln\  odds}$

| Date    | Hours | Charge Amount (\$)| Cost Amount (\$)| Created By | Discipline | Job No. | Reconciled | Scope       |
|---------|-------|---------------|-------------|------------|------------|---------|------------|-------------|
| 2014/09/01 | 4     | 640           | 400         | P12        | Civil      | 1.2.300 | Yes        | Concept     |
| 2014/09/03 | 4.5   | 720           | 450         | P12        | Civil      | 1.2.300 | Yes        | Preliminary |
| 2014/09/03 | 2     | 480           | 320         | P34        | Civil      | 1.2.300 | Yes        | Preliminary |
| 2014/09/08 | 7     | 1120          | 700         | P12        | Civil      | 1.2.300 | Yes        | Preliminary |
| 2014/09/09 | 1     | 160           | 100         | P12        | Civil      | 1.2.300 | Yes        | Preliminary |
| 2014/09/15 | 3     | 390           | 240         | P3         | Structural | 1.2.400 | Yes        | Site        |
| ...     | ...   | ...           | ...         | ...        | ...        |         | ...        | ...         |\
\\

$Overall\ Profit = Revenue\ from\ Project\ Invoices\ - (Employee + Business\ Costs)$

$f(x) = \beta_{0} + \sum_{j = 1}^{p} X_{j} \beta_{j}$

$RSS(\beta) = \sum_{i = 1}^{N} (y_{i} - f(x_{i}))^2$


where $X_{j}$ is simply something

$X_{1}$, include the terms $X_{2} = X_1^2$ and $X_{3} = X_1^3$ to build a third degree polynomial. Interactions between explanatory variables can be modelled by including a terms such as $X_5 = X_4*X_1$ 

$\operatorname{logit}(p) = \log\left(\frac{p}{1-p}\right) = \log(odds)$

$$
\begin{aligned} 
\log(odds) &= \beta_0 + X_1\beta_1 + X_2\beta_2 \\ 
\log\left(\frac{p}{1-p}\right) &= \beta_0 + X_1\beta_1 + X_2\beta_2 \\ 
\log\left(\frac{0.5}{0.5}\right) &= \beta_0 + X_1\beta_1 + X_2\beta_2 \\ 
\log(1) &= \beta_0 + X_1\beta_1 + X_2\beta_2 \\ 
0 &= \beta_0 + X_1\beta_1 + X_2\beta_2 \\ 
X_2\beta_2 &= -\beta_0 - X_1\beta_1 \\ 
X_2 &= -\frac{\beta_0}{\nbeta_2} - X_1\frac{\beta_1}{\beta_2} \\ 
\end{aligned}
$$

$p(X_1 X_2|Y) = p(X_1|Y) \cdot p(X_2|X_1 Y)$


Simple Average:

$Y = \frac{1}{2} \cdot (M_1 + M_2)$

Simple Logistic Regression:

$Y = \beta_0 + \beta_1 M_1 + \beta_2 M_2$

Six blending methods, ranging from simple to complex, were tested using predictions from the top performing individual models. These included simple averaging of the individual model results, building a Logistic Regression model using the individual model results only, a Boosted Tree model using individual model results only, feature weighted linear stacking (FWLS), Random Forests, and Boosted Trees. To explain further, these methods shall be expressed as equations in a problem with three original explanatory variables, $X_1$, $X_2$, $X_3$, and two full sets of predictions from individual predictive models, $M_1$ and $M_2$, with a response variable $Y$. Values in $M_1$ and $M_2$ are probabilities between 0 and 1.

The first two models are simply the average, and weighted average of the three individual model predictions.

Simple Average:

$Y = \frac{1}{2} \cdot (M_1 + M_2)$

Simple Logistic Regression:

$Y = \beta_0 + \beta_1 M_1 + \beta_2 M_2$

The third method builds Boosted Trees from the individual models, i.e. using $M_1$ and $M_2$ only to predict $Y$ in a Boosted Tree model. The last three methods take advantage of potentially meaningful interactions between the individual models' predictions and meta-features. For example, if the $M_1$ model predicted profitability better than $M_2$ for projects in category $a$ of $X_1$, the blending model would take advantage of this interaction. $M_1$ would be weighted higher than $M_2$ for projects where $X_1 = a$. 

A simplified explanation of FWLS is as a Linear Regression where meta-features as well as model predictions from individual models are included as explanatory variables. Then, each meta-feature is interacted with each set of model results [@Sill2009]. A Logistic Regression is performed to weight each term's contribution to the final predictive accuracy and can be expressed for the example problem by the equation below:

$$
\begin{aligned} 
Y &= \beta_0 + \beta_1 M_1 + \beta_2 M_2 + \beta_3 X_1 + \beta_4 X_2 + \beta_5 X_3 + \\
\qquad \beta_6(M_1 \cdot X_1) + \beta_7(M_1 \cdot X_2) + \beta_8(M_1 \cdot X_3) +\\
\qquad \beta_9(M_2 \cdot X_1) + \beta_10(M_2 \cdot X_2) + \beta_11(M_2 \cdot X_3)
\end{aligned}
$$

Random Forests and Boosted Trees were also used to blend meta-features with output from the best models. Feature interaction is performed passively due to the nature of how trees are built. A split in a node determined by one variable is conditional upon the preceding split which was based on another variable and so on. Random Forests and Boosted Tree models are difficult to write as equations, but for the example problem, $X_1$, $X_2$, $X_3$, $M_1$, and $M_2$ would all be included as explanatory variables to predict $Y$.  

